### 概述

本目录根据招聘需求和面经，划分了各个学习方向，内容较多，不一一介绍了。



### 拓展：一些报告

> 参考：[2026.1.10 AGI-Next前沿峰会（唐杰、杨强、杨植麟、林俊旸、姚顺雨）](https://mp.weixin.qq.com/s/NUx4n5j0ftxzZ0Sz29RjOQ?scene=1&click_id=1)

与会专家一致认为，单纯的参数竞赛已成过去，AI正从“聊天机器人”向“干活的智能体”转变，从堆砌算力转向追求AI“自我学习”的新探索。

1、智谱AI（唐杰）

- **技术方向**：让机器像人一样“思考”与“做梦”
- **核心理念**：从“系统1”（直觉思考）向“系统2”（逻辑思考）进化
- **关键技术**：RLVR（可验证奖励的强化学习）、AutoGLM（移动端Agent）
- **创新构想**：引入“机器睡眠”机制，通过自反思和自学习消化数据

2、月之暗面（杨植麟）

- **技术方向**：追求极致的Token效率
- **核心理念**：Scaling Law依然是大模型的第一性原理
- **关键技术**：Muon优化器（2倍Token效率提升）、Key-Value Cross Attention
- **独特观点**：智能是非同质化的，做模型本质是在创造世界观

3、阿里云通义千问（林俊旸）

- **技术方向**：通往通用智能体
- **核心理念**：“模型即产品”，重视开源社区反馈
- **关键技术**：Qwen-3混合架构、理解-生成一体化
- **愿景**：Embodied AI（具身智能）是AI走向现实世界的终极形态

圆桌讨论关键洞察

1、姚顺雨（腾讯AI首席科学家）的观点

- **市场判断**：ToC体验趋于平缓，ToB生产力革命已经开始
- **技术预测**：自主学习将像“间谍渗透”而非“核爆”般渐进发生
- **重要观察**：Coding革命已经开始，企业愿意为确定性支付溢价

2、中美AI差距讨论

- **林俊旸**：中国是“穷人创新”，美国是“富人创新”
- **姚顺雨**：差距主要在冒险精神和研究文化，中国过分关注榜单数字
- **唐杰**：中国00后展现的冒险精神令人欣慰，需要更好的容错环境

3、行业发展趋势

1. **Agent演进**：从工具到“职场人”的四阶段发展
2. **技术范式**：从被动训练转向自主学习
3. **商业落地**：解决长尾需求是Agent的核心价值
4. **开源生态**：中国公司从跟随者转变为推动者



> 参考：[2025.12.26 2026 年 AI 预测：行业将迎来断崖式迭代，最关键的下注机会在哪？](https://mp.weixin.qq.com/s/zB8tVvONI8Mg2pu55jkR_g)

文章基于“海外独角兽”社群的讨论，系统性地展望了 2026 年 AI 领域的核心发展趋势、竞争格局与关键机遇。以下是文章的主要内容总结：

一、巨头竞争格局：从模型之争转向综合博弈

1. **Google**：凭借 Gemini 3 在多模态任务上建立用户心智壁垒；AI 搜索广告的点击率和效果显著优化，可能开辟新收入来源；在视频生成与编辑领域技术管线清晰。挑战在于面临 NVIDIA、Oracle、OpenAI 形成的“反 Google 联盟”，在芯片互联等基础设施上激烈竞争。
2. **OpenAI**：2026 年可能迎来反转。看多方认为其受算力供应链限制的问题将解决，用户基数大、粘性强；看空方则担忧其面临变现压力（如引入广告影响体验）以及多模态能力被 Google 反超。
3. **Anthropic**：在企业级（B 端）市场被普遍低估，其推出的“脚手架”式工具链（如 Skills 功能）更贴合企业实际需求，工程化能力强。
4. **Meta**：AI 已显现巨大商业化潜力，广告系统因 AI 提升效率，年化收入规模有望达 600 亿美元级别，但当前市场可能未充分计价。需应对 TikTok 等对手在广告业务的冲击。
5. **Tesla**：Robotaxi 商业模式可能跑通（单车成本低、回本周期短），FSD 安全性提升；但人形机器人 Optimus 因硬件瓶颈进展低于预期，面临中国供应链的激烈竞争。

二、技术范式竞争：World Model 成为核心胜负手

- **World Model**（世界模型）被视为下一代技术范式的核心，能实现对物理世界的深刻理解，将决定在手机、虚拟世界、游戏、机器人、自动驾驶等下游应用的领先优势。
- **实现路径**：Google 在多模态和视频生成上的突破被寄予厚望；Meta 则走独特路径，通过“Segment Anything”等项目从视觉、听觉等原始感知切入，更贴近人类智能演化方式。

三、AI 应用发展：入口争夺、形态迭代与数据主权

1. **入口之争**： **操作系统派**（如 Apple、Google）：拥有系统级权限和合规优势。 **超级应用派**（如字节跳动的豆包）：试图通过硬件（如 AI 手机）和生态锁定用户，但面临权限不足、隐私合规及商业生态互斥（如被腾讯、阿里封杀）等困境。
2. **形态演进**： **2026 年将是“断崖式迭代”时刻**，行业将全面拥抱 **Agent（智能体）模式**，传统 App 概念可能被淡化。 当前应用多聚焦于“端侧效率优化”（如会议纪要），复杂任务端到端成功率仍低。未来需拓展更碎片化、即时的真实需求场景。
3. **端侧 AI 崛起**：受用户对**数据主权和隐私**的需求推动，计算权力向边缘侧转移。这反过来推高了终端设备（尤其是存储）的硬件需求。

四、基础设施（Infra）：AI 发展的关键瓶颈与投资机会

1. **光通信与互联**：算力集群规模扩大，光模块等需求将爆发式增长（3-5倍）。Google 的 OCS 技术和 NVIDIA 的新一代光互联方案是关注重点。
2. **存储**：需求由 Enterprise AI、多模态、长上下文等驱动，进入“成长趋势”。供给端厂商形成“攻守同盟”控制产能，预计将持续卖方市场，价格看涨。
3. **电力**：取代芯片成为 AI 发展的最大物理瓶颈。电网基础设施老旧问题凸显，催生**微电网（Microgrid）和储能**机会，并利好上游**铜、锂**等大宗商品。

五、垂直领域落地路径

1. **企业服务（Enterprise AI）**：2026 年将加速渗透，在金融、HR、财务等领域出现成熟产品。传统 SaaS 公司面临 IT 预算被 AI 分流的风险。
2. **预测市场**：AI 的介入使其从博彩转向**理性风险对冲工具**（如对冲生活成本上涨），具备金融属性。
3. **支付与电商**：Agent 将在**自动交易、跨支付、自动化电商运营**等泛支付领域落地。

六、监管与风险：可能出现的黑天鹅与新角色

- 中国当前监管存在**前置审批严格但过程监管相对薄弱**的错配风险，可能因高流量应用的合规问题引发“黑天鹅”事件。
- 这可能催生由国家授权、提供“安全合规 API”的**新型“合规基础设施”提供商**（如蚂蚁、阿里等大厂有望扮演此角色）。

七、其他趋势

- **有收入的 AI 应用公司可能反向进入模型研发**（如 Cursor），因其研发成本相对可控。
- **端侧 AI 发展将推动互联网交互形态质变**，AI 将从屏幕渗透到物理世界。

**核心结论**：2026 年 AI 竞争将是技术、商业、生态、基础设施的全方位综合博弈，行业将迎来断崖式迭代。关键机会分布在基础设施（光通信、存储、电力）、下一代技术范式（World Model）、应用新形态（Agent）以及特定垂直领域（企业服务、预测与支付）的落地。



> 参考：[20251230 - Manus被Meta收购，深度对谈创始人肖弘：我更希望做个小公司](https://www.bilibili.com/video/BV1RovaBTEAN)

未来展望：Agent 与软件之间的交互等

管理方面：高频讨论（领导班办公室集中在一起，跟进新技术）、精简制度、高速迭代

资金分配：1/3开工资、1/3买Token、1/3搞营销



> 参考：[20251201 - Manus决定出售前最后的访谈（季逸超 Peak）：啊，这奇幻的2025年漂流啊…](https://www.bilibili.com/video/BV1knvYBDEjs)，持续高能输出4h？？！

个人早期：

- 北大附中，初二开始开发APP赚钱，辍学，浏览器、NLP等等产品
- 想不想将你做过的三件事，浏览器、搜索引擎、语言模型，合为一体
- 猛犸浏览器等、真格、Monica 插件（肖弘）

错误决定：

- 做AI浏览器，1、搞浏览器，却要搞离线；2、AI接管浏览器很奇怪，Agent与用户同时抢一个浏览器；3、AI的真正价值应该在长时间、多步骤的任务上，简单的几步操作，AI相比人更慢。
- “我甚至不能推荐我的亲戚从Chrome改为Arc”，24年9月放弃此产品

其他：

- 故事讲的很清晰，表达能力非常强的CTO，每个阶段的思考和执行非常清晰
- 互补、正常人而非艺术家（相信常识相信团队）、没有乔布斯的命却有乔布斯的病、连续创业者
- 自上而下与自下而上
- 不同阶段不同的场景，采用不同的处理方式，有时是民主式，有时是仁慈的独裁者等等
- 如何选择一家公司？看公司迭代的benchmark

Manus：

- 技术公司/模型公司关注“技术Bet”，但产品公司关注这个有些拧巴
- ChatBot与Agent
- 长规划、高频次、通用
- 确实是Ubuntu虚拟机，即每个用户一个沙盒，甚至Wibe Research可以并行使用沙盒。内部有一个虚拟化团队，使用基于linux内核的虚拟机，没有使用docker容器（基于Cgroup技术），且考虑到很多软件只适配Windows，所以基于Firecracker一个轻量级的虚拟化技术去做，现在Manus支持Windows也支持Linux
- Token消耗量，且input与output阶段与正常用户差距巨大。Token的巨大消耗，迫使模型服务商反向去提升Manaus所需能力
- 通用与垂类
- 认同ReAct，并非一轮做好决策，边做边决策
- MAS下角色定义的弊端，模型比人全能
- （美国）ToB与ToC
- 业务目标与用户画像，系统、环境与用户
- 邀请码与炒作问题，自上而下的推广
- DAU并非追求，高价值事做好，高价值用户服务好

AI更像制造业（这个标题起得不好）：

- 垄断效应（暂时还早）、网络效应
- The Bitter Lesson
- 公司的变化
- 放弃的Feature
- Online Learning

害怕Manus变复杂：

- 团队的协作关系：肖弘、张涛等现状
- 反对投票，异化团队
- 参与公司管理的程度
- 想象三个月后的Agent：Proactiveness、成本降低
- 模型/产品/用户稳态，还没相处AI稳态的约束条件
- Scaling Law是否还有效？
- Agent还是继续爆发、各领域产品
- 对国内外各个大佬/产品的评价
- 如何看待跑路



> 参考：OpenAI 2025年9月的报告：[《How People Use ChatGPT》](https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf)

- 70%的用途与工作无关，AI首先是生活方式
- 实用建议 (Practical Guidance) 、信息查询 (Seeking Information)、写作 (Writing)，加起来占了用户所有对话的将近80%
- 编程相关的用途，只占所有对话的4.2%



> 参考：[2025.9.25 OpenAI两位首席的最新采访实录](https://mp.weixin.qq.com/s/c9xfkGCywKjsvBmklLiRdw)

- **GPT-5 ≠ 简单升级版，而是“推理默认化”**
  - GPT-5 是把推理带入主流的一次尝试，不再让用户纠结该用 GPT 模式还是 o 系列。
- **Benchmark 饱和被官方盖章，新标尺是“经济价值”**
  - 我们关心模型能否发现新事物，并在经济相关领域取得实际进展
- **自动化研究员不是口号，而是 OKR**
  - 先自动化 OpenAI 内部研究，再扩展到其他科学领域。
  - 他们已经在用 o3 做内部 idea generation 和实验设计，并给出量化指标——“推理时间跨度 1–5 小时”。下一步是 1–5 天、1–5 周。如果你做科研 LLM-agent，把任务拆成‘小时级’颗粒度就能与他们对齐，方便未来直接对接 API。
- **RL 仍在“指数区间”，奖励模型将简化**
  - 不要把当下状态视为终局，奖励模型会像当年的微调数据集一样快速商品化。
- **“氛围编码”之后是“氛围研究”**
  - 高中生已经默认 vibe coding，下一步是 vibe researching。
- **编程竞赛被当成“替代基准”**
  - 竞赛提供封装好的测试，可以衡量模型在受限时间内提出新想法的能力。
- **机器人即将回到舞台中央**
  - 除了计算，还要考虑能源等物理约束，机器人技术会在不久的将来成为主要焦点。



> Ask Me Anything 系列，参考：
>
> - [Ask Me Anything Part1](https://mp.weixin.qq.com/s/Z_ypcmGJ8wVH0mAFbzK4rg)
>- [Ask Me Anything Part2](https://mp.weixin.qq.com/s/3r93VrqBUZoCe8vkipiaZw)
> 
> 可以关注这些人的小红书,跟进回答情况，这里挑选一些有意思的QA

方向选择：

```
Q：刘教授 您认为大模型这波红利会持续多久
刘知远：按照国家行动计划要到 2035 年。

Q: 老师，请问具身智能这个方向如何?
刘知远：是 AI 进入物理世界的必由之路。

Q：在毕业工作了有想继续读博的想法，请问目前llm是否有跟传统行业或者新能源领域结合的方向
刘知远：感谢！LLM 预计可以在知识密集型行业发挥作用，着重是将专业知识武装到 LLM 上，你可以从这角度考虑。

Q：课题组没卡，怎么做大模型
刘威杨：如果卡少，那就做大模型的inference加速，这个不怎么吃资源，如果完全没卡但有钱，那就做agent，如果啥也没，建议躺平

Q: 想问一下大佬对具身智能，agentic coding两个方向的前景看法
陈雄辉：我觉得都是好方向，具身战线更长

Q：方博觉得现在多模态生成算是25年入guo jun吗？
方佳瑞：我觉得不算，视频生成才刚刚开始，最终目标应该是世界模型。
```



应用设计相关：

```
Q: 目前各类 computer use、GUI Agent 在实际使用中都还比较 demo，刘老师认为当前制约模型像人（甚至超越人）一样有效使用电脑、手机的关键要素有哪些
刘知远：主要两个思路，一个是行为主义的模仿人类浏览屏幕，就是现在的 GUI-Agent，这个还需要进一步提升模型效率；一个是将 LLM 嵌入 OS，直接从接口层面完成 computer use，也有系统研发的难度。
```



RL相关：

```
Q：刘老师好！请问您对大模型之后的未来发展有什么看法吗？rl是长远方向吗？
刘知远：RL 体现了人工智能的学习范式从过去 Next Token Prediction式的模仿学习，跃迁到了基于大规模强化学习的探索式学习，让大模型有望摆脱已有公开可学习数据日益枯竭的问题。RL 是重要的技术趋势。

Q: xu老师拜读过你各种meta learning和rl的工作，想问问您觉得往这块方向继续科研有潜力吗，对于robotics
徐仲文：有的 可以做到fast adaptation跟generalization

Q：您好！ 请教您是不是传统的pretraining算是走到头了？现在唯一方向是RL?
徐仲文：Ilya有这么说过，但我觉得两者是相辅相成的，RL需要一个很好的基模

Q：1.rl训练中最具决定性的环节是什么，data/reward model or other 2. rl能否真的能突破pretrain model上限获得更强泛化能力还是只是提升下限（pass@k） 3. rl训练对原模型的参数变化影响是不是比较小 4. rl训练的经验心得和方法论 ，如何避免the bitter lesson
徐仲文：data 2. 我相信能突破 可以看我understanding TIR的paper 3. 看MIT那篇不是的 4. 实验会按最合理的方向发展 是很科学的 没有违背常理的实验 所以先想清楚

Q：仲文哥好，我目前研三正在参与秋招，我最近面了一些llm岗发现他们对rl经历都很看重，但是我这块无论是理论还是实操都有点欠缺，请问想短期内对llm rl有一个比较好的认知的话，有什么好的路线吗
徐仲文：verl

Q: 请问你觉得RL的后续出路是什么。在推理这个领域感觉RL的发展已经差不多了
陈雄辉：就rl来说，agent，算法本身，基础架构协同设计。个人认为可能是后面比较重要的

Q: 请问老师 大模型强化学习 后训练需要解决的关键问题有哪些
刘圳：怎样跑得快，怎样做探索，怎样不遗忘。说白了，怎样让老年人变年轻
```



零碎：

```
Q：应对非升即走和无尽的考核不累吗
刘知远：我博士时有位实习导师说过一段话让我受益。他说在大学里也许有 70%的时间在干和指导学生和科研无关的事情，但是正是因为自己喜欢跟学生一起科研，也就愿意为了这份热爱去做那些无关的“洗脏衣服”的事情。我感受，做任何有意义的热爱着的事业，并不意味着 100% 的时间都在做自己感兴趣的事，反而是愿意为了那份热爱甘愿去承担一些附带的条件。共勉。

Q: 怎么优雅地和别人在线技术吵架，吵个三四十分钟而不落下风？我发现我表达能力有限，很难一下子组织出语言捍卫自己技术的逻辑，该怎么提升？
丁霄汉：去reddit评论别人的论文没有novelty，然后你将收获高质量吵架练习

Q: 想问一下，丁博是否认为 llm 存在泡沫现象，现在大厂招 llm 开的价非常高，但是 llm 本身给企业带来的收益有限，不像搜广推那么直接。所以 llm 高薪的情况还能持续多久？
丁霄汉：对跟风搞llm的一些组织来说可能真的是泡沫了，但对真有决心把llm搞好，all in ai的公司来说应该说是刚开始

Q: 这块，感觉没看过有什么好的，可能是我survey不深，所以想问一下。我想问一下，你一般怎么去做survey。
陈雄辉：现在论文太多了，我需要借助工具，力推alphaxiv，semanticscholar，huggingface daily这三个
```



> 参考：[Andrej Karpathy回应强化学习之父Sutton最新观点「LLM是“死路一条”」](https://mp.weixin.qq.com/s/TNaS7QKugqfCke_LG1DJQg)

Richard Sutton 核心观点是，LLMs 的架构从根本上缺乏从实际互动（on-the-job）中持续学习的能力。无论我们如何扩大其规模，它们本质上仍然是在模仿人类数据，而不是通过与世界直接互动来理解世界并实现目标。

Andrej Karpathy 总体上Karpathy认同老爷子对当前LLM研究的批评，但当前的LLM更像是一个向现实妥协的东西，一个比喻：当今的LLM研究并非在创造“动物”，而是在召唤“幽灵“。



Andrej Karpathy首先点明了一个背景：Sutton的“苦涩教训”（The Bitter Lesson）一文，如今已成为前沿LLM圈子里的“圣经”。研究者们会经常讨论某个方法或想法是否足够“bitter lesson pilled”（意即一个方法能够随着算力的增加而自然受益），以此作为判断其是否有效或值得追求的依据。

然而，有趣的是，Sutton本人作为理论的提出者，却并不确定LLM是否真的符合“苦涩教训”。



**Sutton老爷子的“古典主义”愿景：构建“儿童机器”**

- 援引了艾伦·图灵最初构建“儿童机器”的构想——一个能够通过与世界动态互动、从经验中学习的系统。在这个构想中，没有模仿网页内容的巨型预训练阶段。也没有监督微调，Sutton指出这在动物界是不存在的。
- Sutton还强调了一个重要观点：即使你只是将预训练视为强化学习微调之前的先验知识初始化，这种方法也已经被人类偏见所“污染”，从根本上偏离了轨道。在Sutton的世界观里，**AI的一切都源于与世界的强化学习互动**。奖励函数部分来自环境，部分是内在驱动的，例如“乐趣”、“好奇心”，以及与世界模型预测质量相关的因素。并且，智能体在测试时默认是始终在学习的，而不是训练一次就部署



**Karpathy的观点：预训练是我们蹩脚的进化**

- 首先，他认为Sutton的批评并非毫无道理。当前的前沿LLM确实是高度复杂的产物，每个阶段都充满了人性的参与——基础（预训练数据）是人类文本，微调数据是人类策划的，强化学习的环境组合也是由人类工程师调整的
- 我们确实没有一个真正单一、干净、完全符合“苦涩教训”、可以“一键启动”并让其从纯粹的经验中自动学习的算法，那么，这样的算法存在吗？两个常被用来证明其可能性的范例：
  - 第一个是AlphaZero的成功。它完全从零开始，没有任何人类监督就学会了下围棋。但围棋的环境过于简单和封闭，很难将其类比到混乱的现实世界。在算法和分类学上，它本质上只是一个更难的井字游戏
  - 第二个例子是动物，比如松鼠。对此，Karpathy个人也持保留态度。因为动物的产生是通过一种与我们在工业界实际可用的计算过程和约束截然不同的方式
- 由此类比，我们现在的AI也拥有数十亿参数的神经网络。这些参数同样需要丰富、高信息密度的监督信号。我们不可能重新运行一次进化。但我们确实拥有堆积如山的互联网文档
- Karpathy承认，这基本上是动物界所没有的监督学习。但它是一种实用的方法，可以为数十亿参数收集足够的软约束，从而避免从零开始
- 他给出了一个精辟的总结：**“预训练是我们蹩脚的进化（Pretraining is our crappy evolution）。”** 它是解决冷启动问题的一个候选方案，之后再通过更正确的框架（如强化学习）进行微调——这正是当前最先进的LLM实验室普遍在做的事情



**召唤”幽灵”，而非创造“动物”**

- Karpathy认为，我们仍然值得从动物身上汲取灵感。LLM智能体在算法上仍然缺少许多可以从动物智能中借鉴的强大思想。
- 这可能是：幽灵之于动物，如同飞机之于鸟类。



> 参考：[Karpathy 回应争议：RL 不是真的不行，Agent 还需要十年的预测其实很乐观](https://mp.weixin.qq.com/s/3OUQtqM8cr-mqHMNj7Zadw)

一场讨论内容比较广泛的博客。



> 参考：[对腾讯汤道生时隔一年的独家专访：元宝重兵投入这半年](https://mp.weixin.qq.com/s/jSRLLI3-nsEhYoAwL5agaQ)

在2025年春节前夕，腾讯最高层在人工智能战略上，做了两个极为关键的决策：

- 第一，腾讯将旗下聊天机器人产品元宝从TEG（技术工程事业群）划归CSIG，由汤道生率领，这释放了一个信号：元宝将从技术驱动转向产品驱动；
- 第二，就在DeepSeek声名大噪之际，元宝宣布接入满血版DeepSeek，从原本只依赖自研模型的产品策略，转向支持多模型的产品策略。

本次访谈中，汤道生详细复盘了过去半年围绕元宝的变阵、产品抉择和资源调配，To C和To B的协作，以及腾讯这家公司在人工智能变革中的一系列决策与思考。

具体内容：略，业务层面的探讨居多。



> 参考：[2025.10.2 硅谷内部关于 AI Agent 的讨论会实录](https://mp.weixin.qq.com/s/d4MvGLIRNXIYF0O0pCpeIw)

概述：

- **上下文工程 ≠ 提示词技巧**

  - 多位嘉宾都表达了相同的一个观点：其实模型微调一般通常用不上。只要把检索增强生成（RAG）做得到位，就足够用了。但目前大多数 RAG 系统设计都还太过简单
  - 略

- **治理与信任并非“仅限企业”的问题**

  - 安全、溯源和权限管理一次又一次被提及，当前主流的解决方案是：针对结构化和非结构化数据构建统一的元数据目录，并在索引和查询时嵌入访问策略。
  - 信任问题源自于人，而不是技术本身。那些 5% 在生产环境中真正可用的 AI Agent 都有一个共同点：以“**human-in-the-loop**”的方式设计。

- **记忆不仅仅是存储，更是一种架构设计**

  - 记忆的不同层级：用户级、团队级、组织级
  - 利用记忆实现个性化：在应用程序层面，记忆主要有两个作用
    - 根据用户的个人偏好、写作风格、常用格式及专业领域知识来定制化行为
    - 基于事件和元数据提供主动协助，而不仅限于只是被动的聊天回应
  - 设计记忆过程中的冲突与平衡：记忆可以改善用户体验，但过度个性会侵犯隐私，需要限制范围。这里缺失了一个关键的基础要素：一种安全、可跨应用使用、由用户控制的便携式内存层。

- **多模型推理与流程编排模式**

  - 对于不同的任务，采用不同的思路

- **什么时候聊天界面是最合适的？**

  - 对话式交互的价值，在于它能够消除用户的学习成本。但是并非所有场景，聊天界面都是最好的。
  - 关键在于：应该去理解用户使用自然语言的真正意图，并据此进行设计，而非一味地将所有交互都强加于聊天界面之中。

- **一些具有潜力的方向**

  - 上下文可观测性：大多数团队都处于盲目前行的状态，缺乏系统性的方法来评估哪些上下文真正提升了模型性能，哪些反而造成了负面影响。
  - 可组合记忆：记忆是否可以随用户携带（而非依附于应用），具备安全性和可移植性，并支持用户按需选择组织、团队或个人状态的层级？
  - 面向特定领域的领域感知语言：大多数企业用户的需求都是结构化且重复的。与其费力地将自然语言解析成容易出错的 SQL，为何不直接设计更高层次、具备约束安全性且更可靠的专用语言（DSL）呢？
  - 具备延迟感知的用户体验：不同场景下，对于回答的时间要求不同，有的需要自动、主动告诉用户，如预警、开会简报等，有的速度慢却能给用户欣喜的体验，即使延迟 10 秒，只要系统能展示它的思考过程并最终给出有效的答案，用户体验就不会差。

- **生成式 AI 领域的未来方向**

  - 上下文的质量
  - 记忆设计
  - 编排的稳定性
  - 信任的用户体验

- **创始人需要自问的5个关键问题**

  - 我的应用程序的上下文容量是多少？（理想的上下文窗口大小是多少？我又该如何优化其中的内容？)
  - 我的记忆边界在哪里？（哪些信息属于用户级、团队级、组织级？这些数据存储在何处，用户是否可以查看？)
  - 我能否追踪输出结果的来源？（我能通过调试 LLM 的回复，知道具体是哪个输入导致了该回复吗？)
  - 我使用的是单一模型还是多模型？（我是如何根据复杂度、延迟还是成本来分配请求的？)

  - 用户会放心把他们的资金或医疗数据交给我的系统管理吗？（如果不会，我的安全性或反馈机制上还缺失什么？)
