**LangChain (Memory):** æ›´é«˜å±‚çº§çš„æŠ½è±¡ï¼Œå¼€ç®±å³ç”¨çš„ Chain å’Œ Memory ç»„åˆï¼Œå¿«é€Ÿå®ç°åŸºç¡€å¯¹è¯åŠŸèƒ½ã€‚æ ¸å¿ƒæœºåˆ¶æ˜¯å°†å†å²æ‰“åŒ…è¿› Promptã€‚å¯¹å¤æ‚æµç¨‹æ§åˆ¶æœ‰é™ã€‚

**LangGraph (StateGraph):** æ›´ä½å±‚çº§çš„æ§åˆ¶ï¼Œé€šè¿‡å›¾å’ŒçŠ¶æ€æœºæ¨¡å‹æ„å»ºå·¥ä½œæµã€‚å¯¹è¯å†å²æ˜¯ State çš„ä¸€éƒ¨åˆ†ï¼Œå¯ä»¥åœ¨å›¾çš„ä»»ä½•èŠ‚ç‚¹è¢«è®¿é—®å’Œä¿®æ”¹ã€‚é€‚åˆæ„å»ºå¤æ‚çš„ã€æœ‰å†³ç­–èƒ½åŠ›çš„ä»£ç†ã€‚éœ€è¦æ›´å¤šæ‰‹åŠ¨é…ç½®å›¾çš„ç»“æ„ã€‚



# LangChain

## æ ¸å¿ƒæœºåˆ¶

ï¼ˆLangChainæ¶ˆæ¯ç±»å‹ï¼‰LangChain å°†å¯¹è¯æ‹†åˆ†æˆå¤šæ¡æ¶ˆæ¯ï¼ˆ`BaseMessage`ï¼‰ï¼Œå¹¶ç”±ä»¥ä¸‹å­ç±»ä»£è¡¨ä¸åŒè§’è‰²ï¼š

- `SystemMessage`ï¼šç³»ç»Ÿæç¤ºï¼Œç”¨äºè®¾å®šæ•´ä½“å¯¹è¯åŸºè°ƒå’Œè¡Œä¸ºã€‚
- `HumanMessage`ï¼šç”¨æˆ·è¾“å…¥ï¼Œå¯¹åº”è§’è‰² `"user"`ã€‚[Introduction | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/concepts/messages/?utm_source=chatgpt.com)
- `AIMessage`ï¼šæ¨¡å‹è¾“å‡ºï¼Œå¯¹åº”è§’è‰² `"assistant"`ã€‚[Introduction | ğŸ¦œï¸ğŸ”— LangChain](https://python.langchain.com/docs/concepts/messages/?utm_source=chatgpt.com)
- å¦å¤–è¿˜æœ‰ `FunctionMessage`ã€`ToolMessage` ç­‰ï¼Œç”¨äºå‡½æ•°è°ƒç”¨å’Œå·¥å…·é“¾æ‰©å±•ã€‚



## å¤šè½®å¯¹è¯

LangChain è§£å†³å¤šè½®å¯¹è¯çš„ä¸»è¦æ–¹å¼æ˜¯é€šè¿‡å¼•å…¥â€œMemoryâ€ï¼ˆè®°å¿†ï¼‰ç»„ä»¶ã€‚Memory è´Ÿè´£å­˜å‚¨ä¹‹å‰çš„å¯¹è¯è½®æ¬¡ï¼ˆç”¨æˆ·è¾“å…¥å’Œ AI è¾“å‡ºï¼‰ï¼Œå¹¶åœ¨ç”Ÿæˆæ–°çš„ Prompt æ—¶ï¼Œå°†è¿™æ®µå†å²ä¿¡æ¯åŒ…å«è¿›å»ã€‚

**æ ¸å¿ƒæœºåˆ¶ï¼š**

1. Memory ç»„ä»¶ï¼š

    LangChain æä¾›äº†å¤šç§ Memory ç±»ï¼Œä¾‹å¦‚ï¼š

   - `ConversationBufferMemory`: ç®€å•åœ°å­˜å‚¨å®Œæ•´çš„å¯¹è¯å†å²åˆ—è¡¨ã€‚
   - `ConversationSummaryMemory`: éšç€å¯¹è¯è¿›è¡Œï¼Œé€æ­¥ç”Ÿæˆå¯¹è¯çš„æ‘˜è¦ï¼Œé¿å…å†å²è¿‡é•¿ã€‚
   - `ConversationBufferWindowMemory`: å­˜å‚¨æœ€è¿‘ N è½®çš„å¯¹è¯å†å²ï¼Œé¿å…å†å²è¿‡é•¿ã€‚
   - ä»¥åŠå…¶ä»–æ›´å¤æ‚çš„è®°å¿†ç±»å‹ï¼Œå¦‚åŸºäºå®ä½“ã€çŸ¥è¯†å›¾è°±ç­‰ã€‚

2. **é›†æˆåˆ° Chain ä¸­ï¼š** è¿™äº› Memory ç»„ä»¶é€šå¸¸ä¸ LangChain çš„ `Chain` ç»“åˆä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯è®¾è®¡ç”¨äºå¯¹è¯çš„ Chainï¼Œå¦‚ `ConversationChain` æˆ–ç”¨äºæ„å»ºå¯¹è¯ä»£ç†çš„ `AgentExecutor`ã€‚

3. **Prompt Templateï¼š** ç”¨äºå¯¹è¯çš„ Prompt Template ä¼šè®¾è®¡ä¸€ä¸ªç‰¹å®šçš„å˜é‡ï¼ˆé€šå¸¸æ˜¯ `history` æˆ– `chat_history`ï¼‰ï¼Œç”¨äºæ¥æ”¶ Memory ç»„ä»¶æä¾›çš„å†å²ä¿¡æ¯ã€‚

4. è¿è¡Œæµç¨‹ï¼š

   - ç”¨æˆ·è¾“å…¥æ–°çš„æ¶ˆæ¯ã€‚
   - Chain/Agent ä»å…³è”çš„ Memory ä¸­è·å–å½“å‰çš„å¯¹è¯å†å²ã€‚
   - Chain/Agent å°†å†å²ä¿¡æ¯ã€ç”¨æˆ·æ–°è¾“å…¥ä»¥åŠå…¶ä»–å¯èƒ½çš„ä¸Šä¸‹æ–‡ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„ Promptã€‚
   - è¿™ä¸ª Prompt è¢«å‘é€ç»™ LLM è¿›è¡Œå¤„ç†ã€‚
   - LLM ç”Ÿæˆå›å¤ã€‚
   - Chain/Agent å°†ç”¨æˆ·æ–°è¾“å…¥å’Œ LLM çš„å›å¤æ·»åŠ åˆ° Memory ä¸­ï¼Œæ›´æ–°å¯¹è¯å†å²ã€‚
   - Chain/Agent å°† LLM çš„å›å¤è¿”å›ç»™ç”¨æˆ·ã€‚

æœ¬è´¨ä¸Šï¼ŒLangChain çš„ Memory æœºåˆ¶æ˜¯é€šè¿‡åœ¨æ¯æ¬¡è°ƒç”¨ LLM æ—¶ï¼Œå°†å®Œæ•´çš„ï¼ˆæˆ–æ‘˜è¦çš„ã€éƒ¨åˆ†çš„ï¼‰å¯¹è¯å†å²ä½œä¸º Prompt çš„ä¸€éƒ¨åˆ†ä¼ é€’è¿›å»ï¼Œä»è€Œæ¨¡æ‹Ÿâ€œè®°å¿†â€çš„æ•ˆæœã€‚



ç¤ºä¾‹ä»£ç ï¼š

```
import os
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import PromptTemplate

# 1. åˆå§‹åŒ– Memory
# memory_key="history" æ˜¯ Prompt Template ä¸­å¼•ç”¨å†å²å˜é‡çš„åå­—
memory = ConversationBufferMemory(memory_key="history")

# 2. åˆå§‹åŒ– LLM
os.environ["OPENAI_API_KEY"] = "***"
llm = ChatOpenAI(
    base_url="https://openrouter.ai/api/v1",
    model_name="qwen/qwen-2.5-72b-instruct",
    temperature=0.7
)

# 3. å®šä¹‰ Prompt Template
# {history} ä¼šè¢« Memory è‡ªåŠ¨å¡«å……
# {input} ä¼šè¢«ç”¨æˆ·å½“å‰è¾“å…¥å¡«å……
template = """You are a friendly AI assistant.
    Current conversation:
    {history}
    Human: {input}
    AI:
"""

prompt = PromptTemplate(
    input_variables=["history", "input"],
    template=template
)

# 4. åˆå§‹åŒ– Conversation Chain
# å°† LLM, Memory å’Œ Prompt Template å…³è”èµ·æ¥
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    prompt=prompt,
    verbose=True  # è®¾ç½®ä¸º True å¯ä»¥çœ‹åˆ°å®Œæ•´çš„ Prompt å’Œè¿‡ç¨‹
)

# 5. è¿›è¡Œå¤šè½®å¯¹è¯
print("--- ç¬¬ä¸€æ¬¡å¯¹è¯ ---")
response1 = conversation.invoke("ä½ å¥½ï¼Œæˆ‘å«å°æ˜ã€‚")
print("AI:", response1['response'])
print("-" * 20)

print("--- ç¬¬äºŒæ¬¡å¯¹è¯ ---")
# æ³¨æ„ï¼šç¬¬äºŒæ¬¡å¯¹è¯æ—¶ï¼Œmemory ä¸­å·²ç»æœ‰äº†ç¬¬ä¸€æ¬¡å¯¹è¯çš„å†å²
response2 = conversation.invoke("ä½ è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ")
print("AI:", response2['response'])
print("-" * 20)

print("--- ç¬¬ä¸‰æ¬¡å¯¹è¯ ---")
response3 = conversation.invoke("ä½ è§‰å¾—ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
print("AI:", response3['response'])
print("-" * 20)

# å¯ä»¥æŸ¥çœ‹ Memory ä¸­å­˜å‚¨çš„å†å²
print("\n--- Memory ä¸­çš„å†å² ---")
print(memory.load_memory_variables({}))

```

ç¤ºä¾‹ç»“æœï¼š

![image-20250423104514246](./assets/image-20250423104514246.png)







# LangGraph

LangGraphåŸºäºæœ‰å‘æ— ç¯å›¾ (DAG) æˆ–æœ‰çŠ¶æ€å›¾ (StateGraph) çš„æ¦‚å¿µã€‚LangGraph å¤„ç†å¤šè½®å¯¹è¯çš„æ–¹å¼æ˜¯å°†æ•´ä¸ªå¯¹è¯è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªçŠ¶æ€æœºï¼Œå¹¶å°†å¯¹è¯å†å²ä½œä¸ºçŠ¶æ€çš„ä¸€éƒ¨åˆ†æ¥ç®¡ç†ã€‚

## æ ¸å¿ƒæœºåˆ¶

**æ ¸å¿ƒæœºåˆ¶ï¼š**

1. **StateGraphï¼š** LangGraph çš„æ ¸å¿ƒã€‚å®ƒå®šä¹‰äº†å·¥ä½œæµçš„å„ä¸ªçŠ¶æ€ (`State`)ã€èŠ‚ç‚¹ (`Nodes`) å’ŒèŠ‚ç‚¹ä¹‹é—´çš„è½¬ç§»è§„åˆ™ (`Edges`)ã€‚

2. **Stateï¼š** å®šä¹‰äº†æ•´ä¸ªå·¥ä½œæµçš„å½“å‰çŠ¶æ€ï¼Œå®ƒæ˜¯ä¸€ä¸ª Python å­—å…¸æˆ– Pydantic æ¨¡å‹ï¼Œå¯ä»¥åŒ…å«ä»»ä½•éœ€è¦è·¨æ­¥éª¤ä¼ é€’çš„ä¿¡æ¯ï¼Œ**å…¶ä¸­æœ€é‡è¦çš„å°±æ˜¯å¯¹è¯å†å² (`messages`)**ã€‚é™¤äº†æ¶ˆæ¯å†å²ï¼ŒState è¿˜å¯ä»¥åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ã€å†³ç­–æ ‡å¿—ã€è®¡æ•°å™¨ç­‰ç­‰ã€‚

3. Nodesï¼š

    å›¾ä¸­çš„èŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªæ“ä½œæˆ–æ­¥éª¤ï¼Œä¾‹å¦‚ï¼š

   - è°ƒç”¨ LLMã€‚
   - è°ƒç”¨å·¥å…·ã€‚
   - è¿›è¡Œåˆ¤æ–­æˆ–è·¯ç”±ï¼ˆæ ¹æ®çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥ï¼‰ã€‚
   - äººç±»ä»‹å…¥ã€‚
   - æ•°æ®å¤„ç†ã€‚ èŠ‚ç‚¹å‡½æ•°æ¥æ”¶å½“å‰çš„ `State` ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ›´æ–°åçš„ `State` æˆ–ä¸€ä¸ª `State` çš„æ›´æ–°å­—å…¸ã€‚

4. Edgesï¼š

    å®šä¹‰äº†èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥ã€‚å¯ä»¥æ˜¯ï¼š

   - **Conditional Edgesï¼š** æ ¹æ®èŠ‚ç‚¹å‡½æ•°çš„è¿”å›å€¼ï¼ˆé€šå¸¸ç”¨äºè·¯ç”±ï¼‰æˆ–å½“å‰ State çš„å†…å®¹æ¥å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚
   - **Always Edgesï¼š** æ— æ¡ä»¶åœ°è½¬ç§»åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚

5. **Checkpointing (å¯é€‰ä½†æ¨èç”¨äºæŒä¹…åŒ–å¯¹è¯)ï¼š** LangGraph æ”¯æŒå°†å½“å‰ State ä¿å­˜åˆ°å­˜å‚¨ä¸­ï¼Œä»¥ä¾¿åœ¨åç»­è°ƒç”¨æ—¶åŠ è½½ï¼Œå®ç°çœŸæ­£çš„è·¨ä¼šè¯çš„å¤šè½®å¯¹è¯æŒä¹…æ€§ã€‚

6. è¿è¡Œæµç¨‹ï¼š

   - ç”¨æˆ·è¾“å…¥æ–°çš„æ¶ˆæ¯ã€‚
   - å·¥ä½œæµä»¥ä¸€ä¸ªåˆå§‹ State å¼€å§‹ï¼ˆåŒ…å«æ–°çš„ç”¨æˆ·æ¶ˆæ¯å’Œä¹‹å‰çš„å†å²ï¼Œå¦‚æœä» Checkpointing åŠ è½½ï¼‰ã€‚
   - å›¾ä» Entry Point å¼€å§‹æ‰§è¡Œã€‚
   - æ‰§è¡Œå½“å‰èŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹å‡½æ•°æ ¹æ®è¾“å…¥ State è¿›è¡Œå¤„ç†ï¼ˆä¾‹å¦‚ï¼Œè°ƒç”¨ LLM å¹¶å°† AI å›å¤æ·»åŠ åˆ° State çš„ `messages` ä¸­ï¼‰ã€‚
   - èŠ‚ç‚¹å‡½æ•°è¿”å› State çš„æ›´æ–°ã€‚
   - LangGraph æ›´æ–° Stateã€‚
   - æ ¹æ® Edges å®šä¹‰çš„è§„åˆ™ï¼Œå†³å®šä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹ã€‚
   - é‡å¤æ‰§è¡ŒèŠ‚ç‚¹ï¼Œç›´åˆ°è¾¾åˆ°ä¸€ä¸ª Finish Point æˆ–è¿›å…¥ä¸€ä¸ªå¾ªç¯ï¼ˆAgentic è¡Œä¸ºï¼‰ã€‚
   - æœ€ç»ˆçš„ Stateï¼ˆåŒ…å«å®Œæ•´çš„å¯¹è¯å†å²å’Œä»»ä½•å…¶ä»–æ›´æ–°ï¼‰å¯ä»¥è¢«ä¿å­˜ï¼ˆå¦‚æœä½¿ç”¨ Checkpointingï¼‰æˆ–è¿”å›ã€‚

LangGraph çš„ä¼˜åŠ¿åœ¨äºå®ƒæä¾›äº†å¯¹å·¥ä½œæµå’ŒçŠ¶æ€çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œç‰¹åˆ«é€‚åˆæ„å»ºå¤æ‚çš„ä»£ç†ï¼Œè¿™äº›ä»£ç†å¯èƒ½éœ€è¦åœ¨å¯¹è¯è¿‡ç¨‹ä¸­å¤šæ¬¡è°ƒç”¨å·¥å…·ã€è¿›è¡Œå†…éƒ¨æ€è€ƒæˆ–æ ¹æ®æƒ…å†µé‡‡å–ä¸åŒçš„è¡ŒåŠ¨ã€‚å¯¹è¯å†å²ä½œä¸º State çš„ä¸€éƒ¨åˆ†ï¼Œåœ¨æ•´ä¸ªå›¾çš„æ‰§è¡Œè¿‡ç¨‹ä¸­è‡ªç„¶åœ°ä¼ é€’å’Œæ›´æ–°ã€‚



## å¤šè½®å¯¹è¯

ç¤ºä¾‹ä»£ç ï¼š

```
import operator
import os
from typing import Annotated, Sequence, TypedDict

from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END


# 1. å®šä¹‰ State
# State æ˜¯ä¸€ä¸ª TypedDictï¼Œå¿…é¡»åŒ…å« messages
class ChatState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]  # ä½¿ç”¨ Annotated å’Œ operator.add ç¡®ä¿æ–°æ¶ˆæ¯æ˜¯æ·»åŠ åˆ°åˆ—è¡¨è€Œä¸æ˜¯æ›¿æ¢


# 2. å®šä¹‰ä¸€ä¸ªèŠ‚ç‚¹å‡½æ•°ï¼šè°ƒç”¨ LLM
def call_llm(state: ChatState) -> ChatState:
    """
    è°ƒç”¨ LLM å¹¶å°†å›å¤æ·»åŠ åˆ° State çš„ messages ä¸­
    """
    os.environ["OPENAI_API_KEY"] = "***"
    llm = ChatOpenAI(
        base_url="https://openrouter.ai/api/v1",
        model_name="qwen/qwen-2.5-72b-instruct",
        temperature=0.7
    )
    messages = state['messages']
    response = llm.invoke(messages)  # LLM æ¥æ”¶ State ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
    return {"messages": [response]}  # è¿”å› State çš„æ›´æ–°ï¼Œå°† LLM çš„å›å¤æ·»åŠ åˆ° messages ä¸­


# 3. æ„å»º StateGraph
graph_builder = StateGraph(ChatState)
graph_builder.add_node("llm", call_llm)  # æ·»åŠ ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå‘½åä¸º "llm"
graph_builder.set_entry_point("llm")  # è®¾ç½®å…¥å£ç‚¹ä¸º "llm"
graph_builder.set_finish_point("llm")  # è®¾ç½®å‡ºå£ç‚¹ä¸º "llm" (å¯¹äºè¿™ä¸ªç®€å•çš„ä¾‹å­ï¼ŒLLM è°ƒç”¨åå³ç»“æŸ)

# 4. ç¼–è¯‘å›¾
app = graph_builder.compile()

# 5. è¿›è¡Œå¤šè½®å¯¹è¯ (æ‰‹åŠ¨ç®¡ç† State)
print("--- ç¬¬ä¸€æ¬¡å¯¹è¯ ---")
# åˆå§‹ State åªæœ‰ç”¨æˆ·æ¶ˆæ¯
initial_state1 = {"messages": [HumanMessage(content="ä½ å¥½ï¼Œæˆ‘å«å°æã€‚")]}
output_state1 = app.invoke(initial_state1)
print("State after turn 1:", output_state1)  # åŒ…å« Human å’Œ AI çš„æ¶ˆæ¯

print("\n--- ç¬¬äºŒæ¬¡å¯¹è¯ ---")
# ç¬¬äºŒæ¬¡å¯¹è¯çš„åˆå§‹ State æ˜¯ç¬¬ä¸€æ¬¡å¯¹è¯çš„æœ€ç»ˆ Stateï¼Œå¹¶åŠ ä¸Šæ–°çš„ç”¨æˆ·æ¶ˆæ¯
messages_after_turn1 = output_state1['messages']
initial_state2 = {"messages": messages_after_turn1 + [HumanMessage(content="ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ")]}
output_state2 = app.invoke(initial_state2)
print("State after turn 2:", output_state2)  # åŒ…å«ç¬¬ä¸€æ¬¡å’Œç¬¬äºŒæ¬¡çš„ Human å’Œ AI æ¶ˆæ¯

print("\n--- ç¬¬ä¸‰æ¬¡å¯¹è¯ ---")
messages_after_turn2 = output_state2['messages']
initial_state3 = {"messages": messages_after_turn2 + [HumanMessage(content="ä»Šå¤©å¤©æ°”çœŸå¥½ã€‚")]}
output_state3 = app.invoke(initial_state3)
print("State after turn 3:", output_state3)  # åŒ…å«æ‰€æœ‰æ¶ˆæ¯

# æå–æœ€åä¸€æ¡ AI å›å¤
last_ai_message = next((msg for msg in reversed(output_state3['messages']) if isinstance(msg, AIMessage)), None)
if last_ai_message:
    print("\nAI çš„æœ€åå›å¤:", last_ai_message.content)

```

ç¤ºä¾‹ç»“æœï¼š

- `app.invoke(initial_state)` è¿è¡Œå›¾ä¸€æ¬¡ã€‚å®ƒä»å…¥å£ç‚¹å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹ï¼Œæ›´æ–° Stateï¼Œç›´åˆ°åˆ°è¾¾å‡ºå£ç‚¹ã€‚æ¯æ¬¡è¿è¡Œ `invoke` éƒ½ä¼šè¿”å›æœ€ç»ˆçš„ `State`ã€‚
- ä¸ºäº†æ¨¡æ‹Ÿå¤šè½®å¯¹è¯ï¼Œæˆ‘ä»¬åœ¨æ¯æ¬¡è°ƒç”¨ `invoke` åï¼Œæ‰‹åŠ¨è·å–ä¸Šä¸€æ¬¡è°ƒç”¨çš„æœ€ç»ˆ `State` ä¸­çš„ `messages`ï¼ŒåŠ å…¥æ–°çš„ `HumanMessage`ï¼Œç„¶åå°†å…¶ä½œä¸ºä¸‹ä¸€æ¬¡ `invoke` çš„ `initial_state`ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½¿ç”¨ Checkpointing å¯ä»¥è‡ªåŠ¨å®Œæˆè¿™ä¸ªè¿‡ç¨‹ï¼ŒLangGraph ä¼šè´Ÿè´£åŠ è½½å’Œä¿å­˜ Stateã€‚

![image-20250423112030299](./assets/image-20250423112030299.png)



# æ¨¡å‹æœåŠ¡å•†

é’ˆå¯¹OpenAIã€Geminiã€Claudeç­‰æ¨¡å‹æœåŠ¡ï¼Œé’ˆå¯¹å…¶è¿”å›ç»“æœï¼Œå¦‚ä½•åˆ¤æ–­æ˜¯thinkéƒ¨åˆ†ã€tooléƒ¨åˆ†ã€å›ç­”éƒ¨åˆ†ï¼Ÿ

ä¸åŒå¤§æ¨¡å‹æœåŠ¡ï¼ˆOpenAIã€Anthropic Claudeã€Google Geminiï¼‰åœ¨æ¥å£è¿”å›æ—¶ï¼Œé€šå¸¸éƒ½ä¼šæŠŠè¾“å‡ºç»“æ„åŒ–ï¼Œå¸¸è§å‡ å®¶æ¨¡å‹çš„åŒºåˆ«ï¼š

| æœåŠ¡å•† | æœ€ç»ˆå›ç­” (Final)      | å·¥å…·è°ƒç”¨ (Tool)            | æ€è€ƒé“¾ (Think)                               |
| ------ | --------------------- | -------------------------- | -------------------------------------------- |
| OpenAI | `content.type="text"` | `content.type="tool_call"` | `content.type="reasoning"`ï¼ˆæ‘˜è¦ï¼Œä¸æ˜¯å…¨éƒ¨ï¼‰ |
| Claude | `content.type="text"` | `content.type="tool_use"`  | âŒ ä¸æä¾›                                     |
| Gemini | `parts[].text`        | `parts[].function_call`    | `parts[].explanation`ï¼ˆå¯é€‰æ‘˜è¦ï¼‰            |

æ³¨æ„ï¼š

- **think éƒ¨åˆ†**ï¼šå¤§éƒ¨åˆ†å‚å•†éšè—ï¼Œåªæä¾›ã€Œç²¾ç®€ç‰ˆæ¨ç†æ‘˜è¦ã€ï¼ŒçœŸæ­£çš„å®Œæ•´ chain-of-thought å¯¹å¤–ä¸å¯è§ã€‚



