参考：

- https://learnprompting.org/zh-Hans/docs/introduction
- https://www.promptingguide.ai/zh
- https://platform.openai.com/docs/guides/prompt-engineering#six-strategies-for-getting-better-results



六种策略：

- [在查询中包含详细信息以获取更相关的答案](https://platform.openai.com/docs/guides/prompt-engineering#tactic-include-details-in-your-query-to-get-more-relevant-answers)
- [要求模型采用角色](https://platform.openai.com/docs/guides/prompt-engineering#tactic-ask-the-model-to-adopt-a-persona)
- [使用分隔符清楚地指示输入的不同部分](https://platform.openai.com/docs/guides/prompt-engineering#tactic-use-delimiters-to-clearly-indicate-distinct-parts-of-the-input)
- [指定完成任务所需的步骤](https://platform.openai.com/docs/guides/prompt-engineering#tactic-specify-the-steps-required-to-complete-a-task)
- [提供示例](https://platform.openai.com/docs/guides/prompt-engineering#tactic-provide-examples)
- [指定所需的输出长度](https://platform.openai.com/docs/guides/prompt-engineering#tactic-specify-the-desired-length-of-the-output)

更详细的策略，见下文。



## 模型参数设置

参考：https://www.promptingguide.ai/zh/introduction/settings

- Temperature：
  - 简单来说，`temperature` 的参数值越小，模型就会返回越确定的一个结果。
  - 应对如论文撰写等任务，我们可以设置更低的 `temperature` 值，以促使模型基于事实返回更真实和简洁的结果，也就是回答更严谨、思维不发散，应对广告文案撰写，可以设置更高的 `temperature` 值，发挥思维。
- **Top_p**：
  - 同样，使用 `top_p`（与 `temperature` 一起称为核采样（nucleus sampling）的技术），可以用来控制模型返回结果的确定性。如果你需要准确和事实的答案，就把参数值调低。如果你在寻找更多样化的响应，可以将其值调高点。
  - **一般建议是改变 Temperature 和 Top P 其中一个参数就行，不用两个都调整。**
- Max Length：
  - 您可以通过调整 `max length` 来控制大模型生成的 token 数。指定 Max Length 有助于防止大模型生成冗长或不相关的响应并控制成本。
- **Stop Sequences**：
  - `stop sequence` 是一个字符串，可以阻止模型生成 token，指定 `stop sequences` 是控制大模型响应长度和结构的另一种方法。例如，您可以通过添加 “11” 作为 `stop sequence` 来告诉模型生成不超过 10 个项的列表。
- **Frequency Penalty**：
  - `frequency penalty` 是对下一个生成的 token 进行惩罚，这个惩罚和 token 在响应和提示中已出现的次数成比例， `frequency penalty` 越高，某个词再次出现的可能性就越小，这个设置通过给 重复数量多的 Token 设置更高的惩罚来减少响应中单词的重复。
- **Presence Penalty**：
  - `presence penalty` 也是对重复的 token 施加惩罚，但与 `frequency penalty` 不同的是，惩罚对于所有重复 token 都是相同的。出现两次的 token 和出现 10 次的 token 会受到相同的惩罚。 此设置可防止模型在响应中过于频繁地生成重复的词。 如果您希望模型生成多样化或创造性的文本，您可以设置更高的 `presence penalty`，如果您希望模型生成更专注的内容，您可以设置更低的 `presence penalty`。
  - 与 `temperature` 和 `top_p` 一样，**一般建议是改变 `frequency penalty` 和 `presence penalty` 其中一个参数就行，不要同时调整两个。**



## 入门技巧

### 1、指令

需要进行大量实验以找出最有效的方法。以不同的关键词（keywords），上下文（contexts）和数据（data）试验不同的指令（instruction），看看什么样是最适合你特定用例和任务的。通常，上下文越具体和跟任务越相关则效果越好。



有些人建议将指令放在提示的开头。另有人则建议是使用像“###”这样的清晰分隔符来分隔指令和上下文。例如：

```
### 指令 ###
将以下文本翻译成西班牙语：
文本：“hello！”
```



### 2、具体性

要非常具体地说明你希望模型执行的指令和任务。

- 提示越具描述性和详细，结果越好。特别是当你对生成的结果或风格有要求时，这一点尤为重要。
- 包含太多不必要的细节不一定是好的方法。这些细节应该是相关的，并有助于完成手头的任务。这是你需要进行大量实验的事情。我们鼓励大量实验和迭代，以优化适用于你应用的提示。

更重要的是要有一个具有**良好格式和描述性的提示词**。

不存在什么特定的词元（tokens）或关键词（tokens）能确定带来更好的结果。

事实上，在提示中提供示例对于获得特定格式的期望输出非常有效。

例如：

```
提取以下文本中的地名。

所需格式：
地点：<逗号分隔的公司名称列表>

输入：“虽然这些发展对研究人员来说是令人鼓舞的，但仍有许多谜团。里斯本未知的香帕利莫德中心的神经免疫学家 Henrique Veiga-Fernandes 说：“我们经常在大脑和我们在周围看到的效果之间有一个黑匣子。”“如果我们想在治疗背景下使用它，我们实际上需要了解机制。””
```



### 3、避免不明确

给定上述关于详细描述和改进格式的建议，很容易陷入陷阱：想要在提示上过于聪明，从而可能创造出不明确的描述。可以尝试这样做：

```
解释提示工程的概念。保持解释简短，只有几句话，不要过于描述。
```



### 4、做什么还是不做什么

设计提示时的另一个常见技巧是避免说不要做什么，而应该说要做什么。



### 5、应用场景

参考：https://www.promptingguide.ai/zh/introduction/examples



## 进阶技巧

### 1、零样本提示

原文并没有评价零样本提示好与不好、适用于哪些场景。

例如：

```
将文本分类为中性、负面或正面。文本：我认为这次假期还可以。情感：
```

```
中性
```

当零样本不起作用时，建议在提示中提供演示或示例，这就引出了少样本提示。

### 2、少样本提示

以下是在进行少样本学习时关于演示/范例的一些额外提示：

- “标签空间和演示指定的输入文本的分布都很重要（无论标签是否对单个输入正确）”
- 使用的格式也对性能起着关键作用，**即使只是使用随机标签**，这也比没有标签好得多。
- 其他结果表明，从真实标签分布（而不是均匀分布）中选择随机标签也有帮助。

例如：

```
这太棒了！// Negative
这太糟糕了！// Positive
哇，那部电影太棒了！// Positive
多么可怕的节目！//
```

```
Negative
```



标准的少样本提示对许多任务都有效，但仍然不是一种完美的技术，特别是在**处理更复杂的推理任务**时。例如：

```
这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
A：
```

```
是的，这组数字中的奇数加起来是107，是一个偶数。
```



### 3、CoT

#### 基本概念

引入的链式思考（CoT）提示**通过中间推理步骤**实现了复杂的推理能力。您可以**将其与少样本提示相结合**，以获得更好的结果，例如：

```
这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。
A：将所有奇数相加（9、15、1）得到25。答案为False。
这组数中的奇数加起来是偶数：17、10、19、4、8、12、24。
A：将所有奇数相加（17、19）得到36。答案为True。
这组数中的奇数加起来是偶数：16、11、14、4、8、13、24。
A：将所有奇数相加（11、13）得到24。答案为True。
这组数中的奇数加起来是偶数：17、9、10、12、13、4、2。
A：将所有奇数相加（17、9、13）得到39。答案为False。
这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。
A：
```

```
将所有奇数相加（15、5、13、7、1）得到41。答案为False。
```

请记住，作者声称这是足够大的语言模型才会出现的新兴能力。



#### 零样本提示

它基本上涉及将“让我们逐步思考”添加到原始提示中。

```
我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？
让我们逐步思考。
```

```
首先，您从10个苹果开始。
您给了邻居和修理工各2个苹果，所以您还剩下6个苹果。
然后您买了5个苹果，所以现在您有11个苹果。
最后，您吃了1个苹果，所以您还剩下10个苹果。
```



#### Auto-CoT

当使用思维链提示时，这个过程需要手工制作有效且多样化的例子。

一种消除人工的方法，即利用 LLMs “让我们一步一步地思考” 提示来生成一个接一个的推理链。

这种自动过程仍然可能在生成的链中出现错误。为了减轻错误的影响，**演示的多样性**很重要。这项工作提出了Auto-CoT，它对具有多样性的问题进行采样，并生成推理链来构建演示。



Auto-CoT 主要由两个阶段组成：

- 阶段1：**问题聚类**：将给定问题划分为几个聚类
- 阶段2：**演示抽样**：从每组数组中选择一个具有代表性的问题，并使用带有简单启发式的 Zero-Shot-CoT 生成其推理链



#### 自我一致性

自我一致性旨在“替换链式思维提示中使用的天真贪婪解码方法”。其想法是**通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案**。这有助于提高 CoT 提示在涉及算术和常识推理的任务中的性能。



*输出 1：*

```
当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70-3 = 67岁。答案是67。
```

*输出 2：*

```
当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。
```

*输出 3：*

```
当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70/2 = 35岁。答案是35。
```

计算最终答案涉及几个步骤（详见论文），但为了简单起见，我们可以看到已经出现了大多数答案



#### 生成知识提示

问题 + 提示，而非仅问题



#### Prompt Chaining

将任务分解为许多子任务。 确定子任务后，将子任务的提示词提供给语言模型，得到的结果作为新的提示词的一部分

