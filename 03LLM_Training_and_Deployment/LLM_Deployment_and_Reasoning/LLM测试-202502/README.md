> 本测试仅供参考，因为测试时主包也是边学边测的，邪修一个啊

GPU方案：vLLM、SGLang

CPU方案：llama.cpp

特殊方案：Ktransformer

其他：

- LLaMA-Factory + vLLM + Ray：[基于vLLM加速大模型推理并评估性能](https://www.eula.club/blogs/%E5%9F%BA%E4%BA%8EvLLM%E5%8A%A0%E9%80%9F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%B9%B6%E8%AF%84%E4%BC%B0%E6%80%A7%E8%83%BD.html)
- 大模型推理可视化：https://github.com/bbycroft/llm-viz
