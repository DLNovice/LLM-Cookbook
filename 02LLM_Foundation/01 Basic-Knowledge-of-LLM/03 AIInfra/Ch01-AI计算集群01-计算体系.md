> 视频教程：https://www.bilibili.com/video/BV1DX4y1D7PC
>
> Github链接：https://github.com/chenzomi12/AIInfra/tree/main/01AIChip/01Foundation



## AI计算模式



三大范式：监督、无监督、强化学习







## AI芯片关键指标



算力单位：

- OPS：Operations Per Second，处理器每秒的计算次数，进一步，引出TOPS的概念
- MACs：Multiply-Accumulate Operations 乘加累计操作
- FLOPS：Floating Point Operations 浮点运算次数
- MAC：Memory Access Cost 内存占用量





关于时延（Latency）

时延指从用户发起请求到模型返回完整响应所需的时间。根据阶段不同，时延可进一步分为：

- **首 Token 时延（Time to First Token, TTFT）**：从请求开始到生成第一个输出 Token 的时间。
- **生成时延（Per-Token Latency）**：生成后续每个 Token 的时间。
- **端到端时延（End-to-End Latency）**：从请求开始到完整响应返回的总时间（首 Token 时延 + 所有生成时延）。



**时延与其他指标的关系**

(1) Token 输出速度（Tokens/s）

- 正向关系：Token 输出速度越高，生成时延（每个 Token 的时间）越低。
- 例外：首 Token 时延与 Token 输出速度无关，主要取决于模型初始计算和预处理。

(2) 吞吐量（Throughput）

- 权衡关系：吞吐量（单位时间处理的 Token 数或请求数）与时延通常存在矛盾。
  - 高吞吐量需要增大 Batch Size，但会导致单个请求的时延增加（需等待其他请求完成）。
  - 低时延需要小 Batch Size 或实时处理，但会降低吞吐量。
- 动态批处理（Dynamic Batching）：通过合并请求提高吞吐量，同时尽量控制时延（需平衡调度策略）。

(3) 显存占用

- 显存不足会触发显存交换（如CPU-GPU数据传输），大幅增加时延。



优化Latency很重要的两个点：

- 带宽
- 缓存



取计算能力（Compute Capability）和带宽（Bandwidth）的平衡点，让计算性能最大化

![image-20250311101412600](./assets/image-20250311101412600.png)

它们的关系类似于“木桶效应”——整体性能受限于两者的短板

**瓶颈分析：计算与带宽的平衡**

- **计算密集场景**（如矩阵乘法）
  若芯片计算能力远高于带宽，计算单元会因等待数据而空闲，称为 **“内存墙”（Memory Wall）**。
  例如：计算一个FP16矩阵乘法需要2N³ FLOPS，但仅需3N²字节数据，此时算力利用率取决于带宽能否及时供数。
- **带宽密集场景**（如数据搬运、逐元素操作）
  若带宽不足，即使算力再高也无法发挥，例如激活函数（如ReLU）或数据预处理阶段。



**关键指标：运算强度（Operational Intensity）**

定义为单位数据量所需的计算量（FLOPS/Byte）。芯片的 **“屋顶线模型”（Roofline Model）** 可直观展示性能上限：

- **低运算强度任务**（如向量加法）：性能受限于带宽。
- **高运算强度任务**（如大矩阵乘法）：性能受限于计算能力。



**实际案例分析**

**(1) 矩阵乘法优化（GEMM）**

- **问题**：A100的FP16算力为312 TFLOPS，HBM带宽为1.5 TB/s。对于M=K=N=8192的矩阵乘法：
  - 运算强度 = (2×8192³) / (3×8192²×2 bytes) ≈ 2736 FLOPS/Byte。
  - 理论性能上限 = min(312 TFLOPs, 1.5 TB/s ×2736 FLOPs/Byte) = 312 TFLOPs → **计算能力是瓶颈**。
- **优化**：若使用FP8计算，算力提升至624 TFLOPS，但带宽需求减半，运算强度翻倍 → 可能转为带宽瓶颈，需进一步优化数据搬运。

**(2) Transformer推理优化**

- **挑战**：自注意力机制需要频繁读写KV Cache，带宽压力大。
- **解决方案**：
  - FlashAttention：通过分块计算减少HBM访问次数。
  - PagedAttention（vLLM）：动态管理KV Cache显存，避免碎片化。





## 矩阵计算

> AI计算中最核心的计算，软件和硬件如何提高计算能力？





## 比特位宽



三种量化方法



怎么决定Bit Width？哪些时候采用低Bit？
**Bit Width（位宽）** 的选择直接影响计算效率、功耗、内存占用和模型精度。位宽越低，计算速度和能效通常越高，但可能牺牲模型精度；位宽越高，精度保留越好，但资源消耗更大。以下是决定位宽的关键因素和低Bit适用的典型场景：

略





## 计算体系回顾

> 前面的内容比较零散，此小结负责串通

















































