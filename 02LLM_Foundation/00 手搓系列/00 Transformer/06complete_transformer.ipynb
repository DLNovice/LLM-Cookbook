{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整的Transformer模型\n",
    "\n",
    "本notebook实现完整的Transformer模型，包括编码器、解码器和整个序列到序列的架构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 检查设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer架构概述\n",
    "\n",
    "Transformer模型由以下主要组件构成：\n",
    "1. **嵌入层**：将输入token转换为向量表示\n",
    "2. **位置编码**：为序列添加位置信息\n",
    "3. **编码器层**：包含多头注意力和前馈网络\n",
    "4. **解码器层**：包含掩码自注意力、编码器-解码器注意力和前馈网络\n",
    "5. **输出层**：将解码器输出转换为预测概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多头注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # 线性变换\n",
    "        Q = self.w_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.w_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.w_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 注意力计算\n",
    "        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # 合并多头\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, -1, self.d_model\n",
    "        )\n",
    "        \n",
    "        output = self.w_o(attention_output)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super(SimpleLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * np.sqrt(self.d_model)\n",
    "\n",
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len, dropout):\n",
    "        super(TransformerEmbedding, self).__init__()\n",
    "        self.token_embedding = TokenEmbedding(vocab_size, d_model)\n",
    "        self.position_embedding = PositionalEncoding(d_model, max_len)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        token_embedded = self.token_embedding(x)\n",
    "        position_embedded = self.position_embedding(token_embedded)\n",
    "        return self.dropout(position_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = SimpleLayerNorm(d_model)\n",
    "        self.norm2 = SimpleLayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # 自注意力\n",
    "        attn_output, _ = self.self_attention(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 前馈网络\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.encoder_attention = MultiHeadAttention(d_model, n_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = SimpleLayerNorm(d_model)\n",
    "        self.norm2 = SimpleLayerNorm(d_model)\n",
    "        self.norm3 = SimpleLayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
    "        # 掩码自注意力\n",
    "        attn_output, _ = self.self_attention(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 编码器-解码器注意力\n",
    "        attn_output, _ = self.encoder_attention(x, encoder_output, encoder_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 前馈网络\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    完整的Transformer模型\n",
    "    \"\"\"\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, n_heads=8, \n",
    "                 n_encoder_layers=6, n_decoder_layers=6, d_ff=2048, max_len=5000, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.src_embedding = TransformerEmbedding(src_vocab_size, d_model, max_len, dropout)\n",
    "        self.tgt_embedding = TransformerEmbedding(tgt_vocab_size, d_model, max_len, dropout)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.linear = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        # 创建源序列掩码\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def make_tgt_mask(self, tgt):\n",
    "        # 创建目标序列掩码（包括填充掩码和后续掩码）\n",
    "        tgt_pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_len = tgt.size(1)\n",
    "        tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "        tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "        return tgt_mask\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        # 创建掩码\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        \n",
    "        # 编码器\n",
    "        encoder_output = self.src_embedding(src)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoder_output = encoder_layer(encoder_output, src_mask)\n",
    "        \n",
    "        # 解码器\n",
    "        decoder_output = self.tgt_embedding(tgt)\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            decoder_output = decoder_layer(decoder_output, encoder_output, src_mask, tgt_mask)\n",
    "        \n",
    "        # 输出层\n",
    "        output = self.linear(decoder_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试完整的Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试完整的Transformer模型...\n",
      "输入源序列形状: torch.Size([2, 10])\n",
      "输入目标序列形状: torch.Size([2, 8])\n",
      "输出形状: torch.Size([2, 8, 1000])\n",
      "模型参数总数: 45,675,496\n",
      "✓ 模型测试通过！\n"
     ]
    }
   ],
   "source": [
    "# 创建测试数据\n",
    "def create_test_data():\n",
    "    # 模拟词汇表大小\n",
    "    src_vocab_size = 1000\n",
    "    tgt_vocab_size = 1000\n",
    "    \n",
    "    # 创建模拟输入数据\n",
    "    batch_size = 2\n",
    "    src_seq_len = 10\n",
    "    tgt_seq_len = 8\n",
    "    \n",
    "    src = torch.randint(1, src_vocab_size, (batch_size, src_seq_len))\n",
    "    tgt = torch.randint(1, tgt_vocab_size, (batch_size, tgt_seq_len))\n",
    "    \n",
    "    return src, tgt, src_vocab_size, tgt_vocab_size\n",
    "\n",
    "# 测试模型\n",
    "print(\"测试完整的Transformer模型...\")\n",
    "src, tgt, src_vocab_size, tgt_vocab_size = create_test_data()\n",
    "\n",
    "# 创建模型\n",
    "model = Transformer(src_vocab_size, tgt_vocab_size, d_model=512, n_heads=8,\n",
    "                   n_encoder_layers=6, n_decoder_layers=6, d_ff=2048)\n",
    "\n",
    "# 前向传播\n",
    "output = model(src, tgt)\n",
    "print(f\"输入源序列形状: {src.shape}\")\n",
    "print(f\"输入目标序列形状: {tgt.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")\n",
    "print(f\"模型参数总数: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 验证输出维度\n",
    "assert output.shape == (2, 8, 1000), f\"输出形状不正确: {output.shape}\"\n",
    "print(\"✓ 模型测试通过！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单的训练示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行简单训练示例...\n",
      "Epoch 0: Loss = 7.0826\n",
      "Epoch 1: Loss = 7.0855\n",
      "Epoch 2: Loss = 7.0988\n",
      "Epoch 3: Loss = 7.0663\n",
      "Epoch 4: Loss = 7.0071\n",
      "训练完成！平均损失: 7.0681\n"
     ]
    }
   ],
   "source": [
    "# 简单的训练函数\n",
    "def train_simple_example():\n",
    "    # 设置参数\n",
    "    src_vocab_size = 1000\n",
    "    tgt_vocab_size = 1000\n",
    "    d_model = 256\n",
    "    n_heads = 4\n",
    "    n_layers = 3\n",
    "    d_ff = 512\n",
    "    batch_size = 16\n",
    "    num_epochs = 5\n",
    "    \n",
    "    # 创建模型\n",
    "    model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_heads,\n",
    "                       n_layers, n_layers, d_ff)\n",
    "    \n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 训练循环\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 创建模拟数据\n",
    "        src = torch.randint(1, src_vocab_size, (batch_size, 10))\n",
    "        tgt_input = torch.randint(1, tgt_vocab_size, (batch_size, 8))\n",
    "        tgt_output = torch.randint(1, tgt_vocab_size, (batch_size, 8))\n",
    "        \n",
    "        # 前向传播\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(output.view(-1, tgt_vocab_size), tgt_output.view(-1))\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_epochs\n",
    "    print(f\"训练完成！平均损失: {avg_loss:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 运行简单训练示例\n",
    "print(\"运行简单训练示例...\")\n",
    "trained_model = train_simple_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理示例：序列生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试序列生成...\n",
      "源序列: tensor([[645, 297, 428,  44, 266, 917, 789, 168, 961, 480]])\n",
      "生成的序列: tensor([[  1, 892, 947, 306, 450, 445, 686, 686, 686, 686, 686, 686, 686, 686,\n",
      "         686, 686, 686, 686, 686, 686, 686]])\n",
      "生成序列长度: 21\n"
     ]
    }
   ],
   "source": [
    "def generate_sequence(model, src, max_len=50, start_token=1, end_token=2):\n",
    "    \"\"\"\n",
    "    使用Transformer模型生成序列\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 编码源序列\n",
    "        src_mask = model.make_src_mask(src)\n",
    "        encoder_output = model.src_embedding(src)\n",
    "        \n",
    "        for encoder_layer in model.encoder_layers:\n",
    "            encoder_output = encoder_layer(encoder_output, src_mask)\n",
    "        \n",
    "        # 初始化目标序列\n",
    "        batch_size = src.size(0)\n",
    "        tgt = torch.full((batch_size, 1), start_token, dtype=torch.long, device=src.device)\n",
    "        \n",
    "        # 逐步生成序列\n",
    "        for _ in range(max_len):\n",
    "            tgt_mask = model.make_tgt_mask(tgt)\n",
    "            \n",
    "            # 解码器\n",
    "            decoder_output = model.tgt_embedding(tgt)\n",
    "            for decoder_layer in model.decoder_layers:\n",
    "                decoder_output = decoder_layer(decoder_output, encoder_output, src_mask, tgt_mask)\n",
    "            \n",
    "            # 预测下一个token\n",
    "            output = model.linear(decoder_output[:, -1:, :])\n",
    "            next_token = output.argmax(dim=-1)\n",
    "            \n",
    "            # 添加到序列\n",
    "            tgt = torch.cat([tgt, next_token], dim=1)\n",
    "            \n",
    "            # 检查是否生成了结束符\n",
    "            if next_token.item() == end_token:\n",
    "                break\n",
    "        \n",
    "        return tgt\n",
    "\n",
    "# 测试序列生成\n",
    "print(\"测试序列生成...\")\n",
    "src_vocab_size = 1000\n",
    "tgt_vocab_size = 1000\n",
    "\n",
    "# 创建一个小型模型用于测试\n",
    "small_model = Transformer(src_vocab_size, tgt_vocab_size, d_model=256, n_heads=4,\n",
    "                         n_encoder_layers=3, n_decoder_layers=3, d_ff=512)\n",
    "\n",
    "# 创建测试数据\n",
    "test_src = torch.randint(1, src_vocab_size, (1, 10))\n",
    "print(f\"源序列: {test_src}\")\n",
    "\n",
    "# 生成序列\n",
    "generated = generate_sequence(small_model, test_src, max_len=20)\n",
    "print(f\"生成的序列: {generated}\")\n",
    "print(f\"生成序列长度: {generated.size(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行性能分析...\n",
      "\n",
      "测试小型模型...\n",
      "参数数量: 4,722,664\n",
      "平均推理时间: 0.0087秒\n",
      "\n",
      "测试中型模型...\n",
      "参数数量: 45,675,496\n",
      "平均推理时间: 0.0241秒\n",
      "\n",
      "测试大型模型...\n",
      "参数数量: 200,780,776\n",
      "平均推理时间: 0.0726秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 20013 (\\N{CJK UNIFIED IDEOGRAPH-4E2D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 22823 (\\N{CJK UNIFIED IDEOGRAPH-5927}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 25512 (\\N{CJK UNIFIED IDEOGRAPH-63A8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 29702 (\\N{CJK UNIFIED IDEOGRAPH-7406}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 26102 (\\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16584\\1136042145.py:81: UserWarning: Glyph 31186 (\\N{CJK UNIFIED IDEOGRAPH-79D2}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23545 (\\N{CJK UNIFIED IDEOGRAPH-5BF9}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20013 (\\N{CJK UNIFIED IDEOGRAPH-4E2D}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 22823 (\\N{CJK UNIFIED IDEOGRAPH-5927}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25512 (\\N{CJK UNIFIED IDEOGRAPH-63A8}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 29702 (\\N{CJK UNIFIED IDEOGRAPH-7406}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 26102 (\\N{CJK UNIFIED IDEOGRAPH-65F6}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 38388 (\\N{CJK UNIFIED IDEOGRAPH-95F4}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 31186 (\\N{CJK UNIFIED IDEOGRAPH-79D2}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "性能分析完成！\n"
     ]
    }
   ],
   "source": [
    "def analyze_model_performance():\n",
    "    \"\"\"\n",
    "    分析不同大小Transformer模型的性能\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    # 不同配置的模型\n",
    "    configs = [\n",
    "        {\"name\": \"小型\", \"d_model\": 256, \"n_heads\": 4, \"n_layers\": 3, \"d_ff\": 512},\n",
    "        {\"name\": \"中型\", \"d_model\": 512, \"n_heads\": 8, \"n_layers\": 6, \"d_ff\": 2048},\n",
    "        {\"name\": \"大型\", \"d_model\": 768, \"n_heads\": 12, \"n_layers\": 12, \"d_ff\": 3072}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for config in configs:\n",
    "        print(f\"\\n测试{config['name']}模型...\")\n",
    "        \n",
    "        # 创建模型\n",
    "        model = Transformer(1000, 1000, \n",
    "                         d_model=config['d_model'], \n",
    "                         n_heads=config['n_heads'],\n",
    "                         n_encoder_layers=config['n_layers'], \n",
    "                         n_decoder_layers=config['n_layers'], \n",
    "                         d_ff=config['d_ff'])\n",
    "        \n",
    "        # 计算参数数量\n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # 测试推理时间\n",
    "        model.eval()\n",
    "        src = torch.randint(1, 1000, (1, 20))\n",
    "        tgt = torch.randint(1, 1000, (1, 15))\n",
    "        \n",
    "        # 预热\n",
    "        with torch.no_grad():\n",
    "            _ = model(src, tgt)\n",
    "        \n",
    "        # 计时\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(10):\n",
    "                _ = model(src, tgt)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        avg_time = (end_time - start_time) / 10\n",
    "        \n",
    "        results.append({\n",
    "            'name': config['name'],\n",
    "            'params': param_count,\n",
    "            'time': avg_time,\n",
    "            'd_model': config['d_model']\n",
    "        })\n",
    "        \n",
    "        print(f\"参数数量: {param_count:,}\")\n",
    "        print(f\"平均推理时间: {avg_time:.4f}秒\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行性能分析\n",
    "print(\"运行性能分析...\")\n",
    "performance_results = analyze_model_performance()\n",
    "\n",
    "# 可视化结果\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 参数数量对比\n",
    "names = [r['name'] for r in performance_results]\n",
    "params = [r['params'] for r in performance_results]\n",
    "times = [r['time'] for r in performance_results]\n",
    "\n",
    "ax1.bar(names, params)\n",
    "ax1.set_ylabel('参数数量')\n",
    "ax1.set_title('模型参数数量对比')\n",
    "ax1.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "\n",
    "ax2.bar(names, times)\n",
    "ax2.set_ylabel('推理时间(秒)')\n",
    "ax2.set_title('推理时间对比')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"性能分析完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与PyTorch官方实现对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与PyTorch官方实现对比...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Application\\Anaconda\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们的模型输出形状: torch.Size([2, 8, 1000])\n",
      "对比过程中出现错误: the feature number of src and tgt must be equal to d_model\n"
     ]
    }
   ],
   "source": [
    "def compare_with_pytorch_transformer():\n",
    "    \"\"\"\n",
    "    与PyTorch官方Transformer实现对比\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 导入PyTorch的Transformer\n",
    "        from torch.nn import Transformer as PyTorchTransformer\n",
    "        \n",
    "        # 参数设置\n",
    "        d_model = 512\n",
    "        n_heads = 8\n",
    "        n_layers = 6\n",
    "        d_ff = 2048\n",
    "        src_vocab_size = 1000\n",
    "        tgt_vocab_size = 1000\n",
    "        \n",
    "        # 创建我们的实现\n",
    "        our_model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_heads,\n",
    "                               n_layers, n_layers, d_ff)\n",
    "        \n",
    "        # 创建PyTorch官方实现\n",
    "        pytorch_transformer = PyTorchTransformer(d_model=d_model,\n",
    "                                                nhead=n_heads,\n",
    "                                                num_encoder_layers=n_layers,\n",
    "                                                num_decoder_layers=n_layers,\n",
    "                                                dim_feedforward=d_ff,\n",
    "                                                dropout=0.1)\n",
    "        \n",
    "        # 创建测试数据\n",
    "        src = torch.randint(1, src_vocab_size, (10, 2))  # (seq_len, batch_size)\n",
    "        tgt = torch.randint(1, tgt_vocab_size, (8, 2))   # (seq_len, batch_size)\n",
    "        \n",
    "        # 我们的模型需要(batch_size, seq_len)格式\n",
    "        src_our = src.transpose(0, 1)  # (batch_size, seq_len)\n",
    "        tgt_our = tgt.transpose(0, 1)    # (batch_size, seq_len)\n",
    "        \n",
    "        # 测试我们的模型\n",
    "        our_output = our_model(src_our, tgt_our)\n",
    "        print(f\"我们的模型输出形状: {our_output.shape}\")\n",
    "        \n",
    "        # 测试PyTorch官方实现\n",
    "        pytorch_output = pytorch_transformer(src, tgt)\n",
    "        print(f\"PyTorch官方实现输出形状: {pytorch_output.shape}\")\n",
    "        \n",
    "        # 比较参数数量\n",
    "        our_params = sum(p.numel() for p in our_model.parameters())\n",
    "        pytorch_params = sum(p.numel() for p in pytorch_transformer.parameters())\n",
    "        \n",
    "        print(f\"我们的模型参数数量: {our_params:,}\")\n",
    "        print(f\"PyTorch官方实现参数数量: {pytorch_params:,}\")\n",
    "        \n",
    "        print(\"\\n对比完成！两种实现都能正常工作。\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"PyTorch版本不支持官方Transformer实现，跳过对比\")\n",
    "    except Exception as e:\n",
    "        print(f\"对比过程中出现错误: {e}\")\n",
    "\n",
    "# 运行对比\n",
    "print(\"与PyTorch官方实现对比...\")\n",
    "compare_with_pytorch_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本notebook实现了完整的Transformer模型，包括：\n",
    "\n",
    "1. **多头注意力机制**：实现了缩放点积注意力\n",
    "2. **位置编码**：使用正弦和余弦函数添加位置信息\n",
    "3. **编码器层**：包含自注意力和前馈网络\n",
    "4. **解码器层**：包含掩码自注意力、编码器-解码器注意力和前馈网络\n",
    "5. **完整的Transformer模型**：整合所有组件\n",
    "6. **序列生成**：实现了简单的序列生成算法\n",
    "7. **性能分析**：对比了不同大小模型的性能\n",
    "\n",
    "Transformer模型是现代NLP的基础架构，理解其工作原理对于深入学习深度学习非常重要。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
