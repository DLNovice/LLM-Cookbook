## 常用算法

> 参考：[图解各类限流算法｜固定窗口/计数器、滑动窗口、漏桶算法、令牌桶算法](https://www.bilibili.com/video/BV12DUfBAEyr)

一句话总结：**令牌桶是王者，漏桶是保命，滑动窗口是精准，固定窗口是入门。**

| 算法     | 是否平滑 | 是否支持突发 | 实现复杂度 | 常见使用 |
| -------- | -------- | ------------ | ---------- | -------- |
| 固定窗口 | ❌        | ❌            | ⭐          | 简单限流 |
| 滑动窗口 | ✅        | ❌            | ⭐⭐⭐        | 精准限流 |
| 漏桶     | ✅（强）  | ❌            | ⭐⭐         | 下游保护 |
| 令牌桶   | ✅        | ✅            | ⭐⭐⭐        | 网关/API |

现实中**几乎不会只用一种**：

- 网关层：**令牌桶 + IP 限流**
- 应用层：**滑动窗口**
- 下游服务：**漏桶**
- 极端情况：**熔断 + 限流**



### 1、固定窗口/计数器算法

在一个固定时间窗口内，统计请求次数，超过阈值就拒绝。比如：1s 内只能接受100个请求，第101个开始就进行抛弃。

------

#### 工作原理

怎么工作：

- 把时间切成一个个固定窗口（如 `[12:00:00, 12:00:59]`）
- 用一个计数器统计窗口内请求数
- 超过阈值 → 拒绝
- 窗口结束 → 计数器清零

```
|---- 窗口 1 ----|---- 窗口 2 ----|
      100 次           重新开始
```

核型代码逻辑如下：为了并发安全，我们要使用原子操作

```
func (f *FixedWindowCounter) Allow() bool {
 f.mutex.Lock()
defer f.mutex.Unlock()

 now := time.Now()
// 如果超过这段时间范围，重置计数器
if now.Sub(f.lastTime) >= f.window {
  f.counter = 0
  f.lastTime = now
 }
// 检查是否超过限制
if f.counter >= f.limit {
return false
 }
 f.counter++
return true
}
```

------

#### 应用场景

优点

- 实现极其简单
- 性能开销小（一个计数器就行）

缺点（致命）

- 窗口边界问题

比如：

- 12:00:59 来 100 个请求
- 12:01:00 再来 100 个请求

👉 1 秒内 200 个请求直接打爆系统

落地场景

- 对流量不敏感、要求不高的系统
- 内部管理后台
- 临时活动的“兜底限流”
- Nginx `limit_req` 的早期/简化实现思路



### 2、滑动窗口

不再按整点切窗口，而是“动态回看一段时间内的请求数”。

------

#### 工作原理

常见两种实现：

1️⃣ 滑动窗口计数（推荐）

- 把一个大窗口拆成多个小窗口（如 60 个 1 秒窗口）
- 统计最近 N 个小窗口的请求总和

```
[1s][1s][1s][1s] ... [1s]
   ↑   ↑   ↑
   最近 60 秒
```

2️⃣ 请求时间戳队列

- 记录每个请求的时间戳
- 每次请求清理掉窗口外的时间戳
- 判断剩余数量

核心代码逻辑：

```
func (s *SlidingWindowCounter) Allow() bool {
 s.mutex.Lock()
defer s.mutex.Unlock()

 now := time.Now()
 currentWindow := now.Truncate(s.precision).Unix()
 s.cleanExpiredWindows(now)                    // 清理过期的窗口数据
 totalRequests := s.countRequestsInWindow(now) // 计算当前窗口内的总请求数
if totalRequests >= s.limit {                 // 检查是否超过限制
return false
 }
 s.requests[currentWindow]++ // 增加当前窗口的计数
return true
}
```

------

#### 应用场景

优点

- **限流更平滑**
- 基本解决固定窗口的“突刺问题”

缺点

- 实现复杂
- 内存和计算成本更高
- 高并发下维护时间窗口不便宜

落地场景

- API 网关（Spring Cloud Gateway）
- 对稳定性要求高的对外接口
- SaaS 平台的用户级 / IP 级限流
- Redis + Lua 实现分布式滑动窗口



### 3、漏桶算法

> **`大家看到滑动窗口可以很平滑地控制流量，至少可以应对突发的峰值流量。`** 但如果这个窗口如果一开始就被打满了，那么剩下的时间都不可访问了，这似乎有点不讲道理。然后我们就引入了`漏桶算法`。

把请求想象成水：**请求先进入桶里，桶以恒定速度“漏水”处理请求。**“匀速处理”是重点。

------

把水桶逆时针旋转90度来看，是不是很像我们的`MQ消息队列`。雨表示消息队列的大量生产者，桶表示消息队列的存储，水滴表示消息队列的消费者。

所以漏桶算法也具备`削峰填谷`的作用，经过漏桶后请求就能匀速平滑的流出。

1. 启动一个协程定时漏水
2. 如果桶满了，不再给予请求通过，如果没满，则放入桶中等待处理请求
3. 获取桶中的水滴后，对桶内的容量进行扣除，以让下一个请求进行处理

------

#### 工作原理

怎么工作

- 请求进入桶（队列）
- 桶满 → 拒绝请求
- 桶以固定速率处理请求

```
请求 → [ 桶 ] → 以固定速率流出
```

核心代码逻辑如下：

- start 启动漏桶的定时漏水协程

```
func (lb *LeakyBucket) start() {
 lb.mutex.Lock()
if lb.isRunning {
  lb.mutex.Unlock()
return
 }
 lb.isRunning = true
 lb.mutex.Unlock()
gofunc() {
  ticker := time.NewTicker(lb.leakRate)
defer ticker.Stop()
for {
   select {
   case <-ticker.C:
    lb.leak()
   case <-lb.stopCh:
    return
   }
  }
 }()
}
```

- Allow 尝试向桶中添加一个请求，如果桶未满，返回 true；如果桶满了，返回 false

```
func (lb *LeakyBucket) Allow() bool {
 lb.mutex.Lock()
defer lb.mutex.Unlock()

if lb.tokens < lb.capacity {
  lb.tokens++
return true
 }
return false
}
```

- leak 执行漏桶操作，让请求处理完后进行漏桶。

```
func (lb *LeakyBucket) leak() {
 lb.mutex.Lock()
 defer lb.mutex.Unlock()

 if lb.tokens > 0 {
  lb.tokens--
  lb.lastLeak = time.Now()
 }
}
```

------

#### 应用场景

特点

- 无论外部流量多猛，输出永远平滑
- 天生适合削峰填谷

优点

- 非常稳定
- 能保护下游服务

缺点

- 不支持突发流量
- 高峰期大量请求被直接丢弃
- 实时性差（请求可能被排队）

落地场景

- 消息队列消费者限速
- 下游依赖特别脆弱的服务
- 数据同步、日志上报
- 网络设备（路由器、交换机）流控



### 4、令牌桶算法

>虽然漏桶算法可以顺滑处理请求，`但是无法应对突发流量的来袭，并且处理请求会有延迟`。
>
>那什么情况会用漏桶算法呢？我们上面说了，漏桶算法很像消息队列，我们可以想一下我们什么场景下会用消息队列，是不是为了应付一些高流量的场景，避免高流量把下游打满，这是不是对下游的一种保护。`所以其实漏桶算法就是为了保护下游，避免下游打挂，下游不能承受过重的QPS，只能一点一点地喂给下游`
>
>**我们消息队列是为了那些不是很实时的业务，所做的高时延的动作。但对于http请求我们必须要求低时延，不能说我一个请求要等很久，并且漏桶算法也没法处理突发流量，所以就引入了令牌桶算法。**

**漏桶的“反向升级版”**：系统按固定速率生成令牌，请求必须拿到令牌才能执行。

重点：**支持突发流量**

我们可以看到令牌桶是可以处理突发流量，无论桶里的令牌够不够，都能马上给出响应。令牌够，请求，令牌不够，请求够的，不够的直接拒绝，干脆利索。

------

#### 工作原理

怎么工作

- 桶里存令牌
- 按固定速率往桶里放令牌（有上限）
- 请求来了：
  - 有令牌 → 消耗一个，放行
  - 没令牌 → 拒绝或等待

```
令牌生成 → [ 令牌桶 ] → 请求消耗
```

核心代码逻辑：

- start 启动令牌补充协程

```
func (tb *TokenBucket) start() {
 tb.mutex.Lock()
if tb.isRunning {
  tb.mutex.Unlock()
return
 }
 tb.isRunning = true
 tb.mutex.Unlock()

gofunc() {
  ticker := time.NewTicker(tb.refillPeriod)
defer ticker.Stop()

for {
   select {
   case <-ticker.C:
    tb.refill()
   case <-tb.stopCh:
    return
   }
  }
 }()
}
```

- 函数 `AllowN` 尝试获取 n 个令牌

```
func (tb *TokenBucket) AllowN(n int) bool {
 tb.mutex.Lock()
defer tb.mutex.Unlock()

if tb.tokens >= n {
  tb.tokens -= n
return true
 }
return false
}
```

**`与漏桶算法对比，其实令牌桶算法可以应对一些突发的流量，并且支持低时延的响应。`**

------

#### 应用场景

优点

- 支持一定程度的突发请求
- 长期来看仍然是限速的
- 实际生产最常用

缺点

- 实现稍复杂
- 需要精确时间控制

落地场景

- API 网关限流（最主流）
- 用户登录、短信发送
- 支付、下单接口
- Nginx `limit_req`、Guava RateLimiter
- Kubernetes、Envoy



## 应用场景

>架构设计的金句：
>
>- 限流一定要分层做，越靠前越粗，越靠后越精；
>- 越靠用户越讲体验，越靠资源越讲生存。

结合后端架构层：

| 架构层    | 主要目标   | 推荐算法 |
| --------- | ---------- | -------- |
| CDN / WAF | 抗洪水     | 固定窗口 |
| API 网关  | 公平 + SLA | 令牌桶   |
| 应用服务  | 业务保护   | 滑动窗口 |
| 下游依赖  | 稳定输出   | 漏桶     |

以一个电商系统为例：

- **CDN**：IP 固定窗口（10k QPS）
- **网关**：用户级令牌桶（100 QPS）
- **订单服务**：商品级滑动窗口（库存）
- **支付回调**：漏桶（50 TPS）

结果是：

- 洪水被挡在最外面
- 网关保证公平
- 核心业务稳
- 下游服务不被拖死