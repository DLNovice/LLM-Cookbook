社招面试中如何介绍项目？四步骤

- 背景
- 问题
- 怎么解决
- 达到了什么效果

注意事项：

- 不要只侧重业务背景去介绍，要突出问题以及解决问题的思考过程
- 刚工作没多久，不要拿一些高深的方向或者领域做文章



## 综合面经

Github高star面经：Github搜索agent interview、llm intervie等关键词

- https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra01-%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88.md

- https://github.com/WeThinkIn/AIGC-Interview-Book

- https://github.com/wdndev/llm_interview_note

一些面经：

- [一口气刷完 500多道大模型面试题！](https://mp.weixin.qq.com/s/u2hRv1fCylZpgG6P9kNTfw)
- https://zhuanlan.zhihu.com/p/1913298662873863066
- https://www.53ai.com/news/AImianshi/2025060852783.html

- https://mp.weixin.qq.com/s/Q6FPYenia1aHl-8e8Nhx4g

- https://github.com/jingtian11/EasyOffer/tree/main

- https://blog.51cto.com/u_16163442/12396516

- https://fcnisnh9uh54.feishu.cn/wiki/XGkRwrugwisqaokx909caQ4anEb

- [我的秋招经历，大厂AI岗位面试真题总结](https://mp.weixin.qq.com/s/S584V51Vi4qLkejMQ1ibAw)





> 参考：[大模型实习 || 秋招哪些才是大模型算法岗的硬通货？](https://www.bilibili.com/video/BV16nb9zzEwj)

简历准备：起码满足2~3项

- 学历：92、科班
- 论文：大模型相关
- 竞赛：大模型相关
- 实习：2段实习

实操：

- 刷题：Hot100，手写Transformer、MHA等等
- 八股：NLP基础知识等等
- 简历项目：熟悉掌握，并有一定的拓展



## langchain

TODO



## agent

一面：

1、手撕

- m*n的矩阵从左上到右下（只许右、下），路径数量。dfs/dp✔

- 重排链表 ✔


2、拷打项目

- multi-agent的协作

- mcp工具怎么搭建

- agent响应速度多少

- 怎么agent优化响应速度

- 介绍langchain

- mcp工具的响应怎么优化的


二面：拷打项目

- 多智能体框架选型原因

- 多agent协作流程

- 负责上下文的agent崩了咋整，怎么维护可靠性

- 响应速度多少，怎么优化

- agent并发流量、跟踪调用链路

- 这个项目花了多久

- 讲讲大模型部署流程

- 怎么接触的milvus

- 卡尔曼滤波应用场景与原理

- 怎么接触的TensorTR/ONNX，讲讲你的使用流程



## 微调

> 参考：[20241105 - 简历大模型微调这么写就是减分项你可这么改 - 挺逗的汪](https://www.xiaohongshu.com/discovery/item/67298da1000000001b02b61a?source=webshare&xhsshare=pc_web&xsec_token=ABoCZptb29U0QlVOnsh6-VAw-vvhb5XCI7Ge0MlP8_cw4=&xsec_source=pc_share)

苍白的说法：从 xx 任务中，从网络/清洗获取 xx 条数据，微调 xx 模型，业务上提升 xx 个点。

因为微调算法、模型都是现成的，上述说法可以简化为拿着数据直接干就结束了。

一些建议：销售对话业务

- Step1 提取训练数据：让大模型基于PromptEngineering（cot、reflection、多llm一致性、debating等）提取“任务 + pair对”，再让大模型与真人对话时“编写”（相比直接生成，编写更贴合“任务”、面对复杂多样的现实场景更有逻辑）通话内容 



## RAG

> 参考：202411 - 招聘平台智能对话模型 - 挺逗的汪

[整体方案](https://www.xiaohongshu.com/discovery/item/673015f2000000001b02a318?source=webshare&xhsshare=pc_web&xsec_token=ABpwFO8SkpId0VEGId4TsL1DbYzCnNQ5GpQkK4KEeHEuI=&xsec_source=pc_share)：

- 方案：
  - query改写：或者说填空再检索，又或是查询重写策略，非常重要，也是后续步骤的基石，一些细节如下
    - 岗位、地点、年限等改写兼容，比如cv改为视觉算法
    - 岗位需求描述固定格式，后面的语义emb才好训练
  - 意图识别：岗位查询、岗位咨询、岗位统计等等，每个关键词都包含不同的”workflow“
- 难点：数据少且新业务甚至没数据 + 基座大模型不理解各种岗位信息

[检索和评估技术方案](https://www.xiaohongshu.com/discovery/item/67373d37000000001b02ad80?source=webshare&xhsshare=pc_web&xsec_token=AB7QMCwcjzRUvaxirDwM-5kztHQLl85wgULZzOCLhqAT0=&xsec_source=pc_share)：目标2s内输出准确结果

- 检索：采用传统”关键词 + embedding“模式，另外面对的一些问题，如下
  - 岗位缩写：岗位采用二层级类目、关键词匹配岗位
  - 地点匹配：暴力法，树状结构
  - 除了上述硬性条件的检索，还有些涉及一些语意问题的检索需求，比如 xxx，这里采用两种方式
    - 传统关键词匹配：使用 分词/改写/term weighting 那套
    - embedding：
      - 简单微调bge的embedding模型：根据简历内容改写成真人求职的语句→然后用传统检索获得相关岗位→大模型做判定，找到合适的几个岗位→人工check，hard sample挖掘怎么做？
      - 使用emb的检索引擎（向量搜索引擎，用 embedding 来实现语义检索？）
      - 搭建向量检索服务：根据以上两个模型得到的检索结果，用加权策略得到一个排序分
- 评估：除了上述每个环节的评估，如何做整体的端到端的评估
  - 假设只有5个岗位符合要求，但是top10的结果中有无关的，如何知道有几个符合要求的？是召回问题还是数量本身限制？
  - 早起可以先人工写query评估，测试top10内岗位准确度：为了确认是否为召回问题，可以评估top50内是否有相关岗位；为了确定top10内有无错误召回的岗位，则看top100有无相关岗位，有则说明为排序问题，没有则说明只能匹配这么多，定位准确

[基于简历推岗](https://www.xiaohongshu.com/discovery/item/67381635000000001b02f0b6?source=webshare&xhsshare=pc_web&xsec_token=ABOegkezWz2O7Vcm096emjmOQWL_PL5OB0PVOKb9rTV-Y=&xsec_source=pc_share)：

- 前要 - 简历推岗与用户query推岗的区别：本质都是拿简历中的信息去提问，区别在于：1）简历中工作地点等信息没有明确表达；2）工作内容太多容易混淆。这些问题的核心在于信息结构化提取。
- 提取简历信息：初期买API，效果不佳，后续使用开源OCR模型，效果可接受
- 结构化信息提取：
  - 简历标注：略
  - 模型训练：与前面query改写一致。有个细节，大模型由于不理解各个岗位名称导致岗位分类很难，且如何带上岗位介绍，文本太长无法处理，解决方案如下：
    - 方案1 单独训练一个多分类模型：没分简历可能适合多个岗位，所以需多分类，但需要大量数据集，而目前仅有的三四十万数据集中除去比较老、无法使用的简历，剩余不足十万的数据无法完成此任务
    - 方案2 用llm训练一个语义理解的二阶段模型：
      - 一阶段做一节岗位分类，二阶段选取前三岗位的二级岗位分类。
      - 分阶段的原因：一级类目岗位加上介绍在1w字内，二级类目同理。如何训练模型才能达到随意替换岗位信息后准确识别的效果？




> 参考：[20241108 - 简历编大模型rag项目暴露评估问题 - 挺逗的汪](https://www.xiaohongshu.com/discovery/item/672e2f660000000019019d29?source=webshare&xhsshare=pc_web&xsec_token=AB2Qh3s2GG2IBP_LApN3E7i9g6YzDpxM8nU_phSdIdU9c=&xsec_source=pc_share)

评估分两部分：

- 日常自评：日常随便迭代一下，需要定义评指标，如正确性（有没有包含正确答案）、全面性等
- 上线评定：人工评估，并定一个可量化的指标

评估结果如何定义：

- 正确和错误
- 好中差

badcase问题分类：

- 比如分类为基础知识问题、产品对比问题、产品使用问题等

补充：

- 关于大模型自评
  - 计算相似度不太行：1）答案本身不是一句话，是一段话，且一段话里语义顺序可能会不一致，当下embedding 搞不定；2）答案有好中差，有些没有固定答案。
  - 可以找一个更大的模型
  - 检索评估可供参考，如ragas，但是无法作为上线指标，容易背锅
  - 特定领域，可以考虑定性定量后，标注数据训练一个模型，让评估模型的准确率尽可能高，72b的效果可能搞过gpt4



## AI-Infra

> 参考：[如何写一份合格的AI-Infra岗位秋招简历](https://www.bilibili.com/video/BV1iEpgz8EUE?spm_id_from=333.1245.0.0)

略



> 参考：[Ai-Infra面试实录—大模型推理框架开发实习岗位](https://www.bilibili.com/video/BV1VAUKBxEFT)

概述：

- C++
- 结合项目/技术栈，问细节：OpenAI Tnton等
- vLLM核心机制等
- 手搓算子




## AI PM 相关

参考：[AI 产品经理（AI PM）面试必问 30 题](https://mp.weixin.qq.com/s/Yht-hu4568TQC-u4NPrP3A)



## 付费资源概述

>个人片面理解，如有侵犯，立马滑跪删除

概述如下：

- 某书：几个博主笔记都挺全面的，根据课程大纲进行选择
- 丁师兄：涵盖深度学习基础、模型训练、微调与推理优化等主题，内容从基础到进阶均有涉及
- RAG大模型全集：以文档形式整理了 LLM / NLP / RAG / Transformer 相关知识点与面试题，可作为查阅材料
- 西瓜RAG：文档资源为主，可用于较快速地了解 RAG 相关概念
- 智泊AGI：包含文档与视频，主题较全面，包括 LLM 原理、Prompt、RAG（基础与进阶、多模态、评估）、Agent（框架、Function Calling、数据处理）、部署（评估、量化、上线流程）等，可按需选择文档先行浏览
- RAG与Agent性能调优：主要为视频形式，内容以场景示例为主，适合按需求选看
- jk-大模型RAG进阶实战：提供文档，可作为补充材料参考
- 知乎：包含多种形式的资料，可按兴趣选取相关内容
- 聚客AI：重大模型部署、量化与微调等方向
- 卢青博士：以视频为主，包含若干实战项目，可先了解项目结构后再决定是否进一步学习
- LangChain实战项目：要为视频形式，涉及 LangChain、知识图谱、Gradio、向量库、多智能体等，可根据自身关注点选择性观看

- mksz920：视频为主，涉及较多企业场景内容，可按学习重点自行筛选
- 慕课网：以视频为主，内容覆盖面广
- 天机AI：涉包含 SpringAI 等方向的说明文档，结构较清晰，可快速浏览了解整体框架
